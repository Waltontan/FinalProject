{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependents\n",
    "import pandas as pd \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data CSV \n",
    "df_og = pd.read_csv(\"../resources/winequality-red.csv\")\n",
    "df_og.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining X and Y axis for machine learning\n",
    "X = df_og[[\n",
    "    \"fixed acidity\", \n",
    "    \"volatile acidity\", \n",
    "    \"citric acid\", \n",
    "    \"residual sugar\", \n",
    "    \"chlorides\", \n",
    "    \"free sulfur dioxide\", \n",
    "    \"total sulfur dioxide\", \n",
    "    \"density\", \n",
    "    \"pH\", \n",
    "    \"sulphates\",\n",
    "    \"alcohol\"\n",
    "]]\n",
    "\n",
    "y = df_og[\"quality\"].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Data for training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling data to improve machine learning accuracy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "y_scaler = StandardScaler().fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "y_train_scaled = y_scaler.transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3348456451292864"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the linearmodel \n",
    "from sklearn.linear_model import LinearRegression\n",
    "linearmodel = LinearRegression()\n",
    "linearmodel.fit(X_train_scaled, y_train_scaled)\n",
    "linearmodel.score(X_test_scaled, y_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7125"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the RandomForestClassifiermodel \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RandomForestClassifiermodel = RandomForestClassifier(n_estimators=200)\n",
    "RandomForestClassifiermodel.fit(X_train_scaled, y_train)\n",
    "RandomForestClassifiermodel.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0760214 , 0.10135945, 0.07531274, 0.07603893, 0.08249003,\n",
       "       0.06830351, 0.10251071, 0.09086525, 0.07494532, 0.10993799,\n",
       "       0.14221466])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display which category is more important\n",
    "importances = RandomForestClassifiermodel.feature_importances_\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting train and test accuracy for KNN model to determine number of neighbours to use\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 40, 1):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    train_score = knn.score(X_train_scaled, y_train)\n",
    "    test_score = knn.score(X_test_scaled, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "\n",
    "plt.plot(range(1, 40, 1), train_scores, marker='o')\n",
    "plt.plot(range(1, 40, 1), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.585"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the KNN model base on the optimised number of neighbour\n",
    "knn = KNeighborsClassifier(n_neighbors=25)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "train_score = knn.score(X_train_scaled, y_train)\n",
    "test_score = knn.score(X_test_scaled, y_test)\n",
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating encoder for neural network model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# One-hot encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_categorical[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining layers in the neural network model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=11))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=6, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 100)               1200      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 11,906\n",
      "Trainable params: 11,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the neural network model\n",
    "model.compile(optimizer='adam', loss=\"categorical_crossentropy\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "38/38 - 0s - loss: 1.2847 - accuracy: 0.5029\n",
      "Epoch 2/500\n",
      "38/38 - 0s - loss: 1.0094 - accuracy: 0.6063\n",
      "Epoch 3/500\n",
      "38/38 - 0s - loss: 0.9598 - accuracy: 0.6155\n",
      "Epoch 4/500\n",
      "38/38 - 0s - loss: 0.9367 - accuracy: 0.6247\n",
      "Epoch 5/500\n",
      "38/38 - 0s - loss: 0.9114 - accuracy: 0.6339\n",
      "Epoch 6/500\n",
      "38/38 - 0s - loss: 0.8944 - accuracy: 0.6380\n",
      "Epoch 7/500\n",
      "38/38 - 0s - loss: 0.8807 - accuracy: 0.6414\n",
      "Epoch 8/500\n",
      "38/38 - 0s - loss: 0.8663 - accuracy: 0.6489\n",
      "Epoch 9/500\n",
      "38/38 - 0s - loss: 0.8568 - accuracy: 0.6580\n",
      "Epoch 10/500\n",
      "38/38 - 0s - loss: 0.8553 - accuracy: 0.6522\n",
      "Epoch 11/500\n",
      "38/38 - 0s - loss: 0.8347 - accuracy: 0.6539\n",
      "Epoch 12/500\n",
      "38/38 - 0s - loss: 0.8171 - accuracy: 0.6672\n",
      "Epoch 13/500\n",
      "38/38 - 0s - loss: 0.8126 - accuracy: 0.6631\n",
      "Epoch 14/500\n",
      "38/38 - 0s - loss: 0.7988 - accuracy: 0.6781\n",
      "Epoch 15/500\n",
      "38/38 - 0s - loss: 0.7929 - accuracy: 0.6672\n",
      "Epoch 16/500\n",
      "38/38 - 0s - loss: 0.7891 - accuracy: 0.6664\n",
      "Epoch 17/500\n",
      "38/38 - 0s - loss: 0.7727 - accuracy: 0.6806\n",
      "Epoch 18/500\n",
      "38/38 - 0s - loss: 0.7659 - accuracy: 0.6831\n",
      "Epoch 19/500\n",
      "38/38 - 0s - loss: 0.7566 - accuracy: 0.6731\n",
      "Epoch 20/500\n",
      "38/38 - 0s - loss: 0.7547 - accuracy: 0.6856\n",
      "Epoch 21/500\n",
      "38/38 - 0s - loss: 0.7447 - accuracy: 0.6839\n",
      "Epoch 22/500\n",
      "38/38 - 0s - loss: 0.7353 - accuracy: 0.6897\n",
      "Epoch 23/500\n",
      "38/38 - 0s - loss: 0.7238 - accuracy: 0.6914\n",
      "Epoch 24/500\n",
      "38/38 - 0s - loss: 0.7161 - accuracy: 0.7023\n",
      "Epoch 25/500\n",
      "38/38 - 0s - loss: 0.7013 - accuracy: 0.7031\n",
      "Epoch 26/500\n",
      "38/38 - 0s - loss: 0.6929 - accuracy: 0.7139\n",
      "Epoch 27/500\n",
      "38/38 - 0s - loss: 0.6915 - accuracy: 0.7064\n",
      "Epoch 28/500\n",
      "38/38 - 0s - loss: 0.6763 - accuracy: 0.7073\n",
      "Epoch 29/500\n",
      "38/38 - 0s - loss: 0.6730 - accuracy: 0.7181\n",
      "Epoch 30/500\n",
      "38/38 - 0s - loss: 0.6621 - accuracy: 0.7189\n",
      "Epoch 31/500\n",
      "38/38 - 0s - loss: 0.6645 - accuracy: 0.7398\n",
      "Epoch 32/500\n",
      "38/38 - 0s - loss: 0.6482 - accuracy: 0.7331\n",
      "Epoch 33/500\n",
      "38/38 - 0s - loss: 0.6415 - accuracy: 0.7281\n",
      "Epoch 34/500\n",
      "38/38 - 0s - loss: 0.6298 - accuracy: 0.7398\n",
      "Epoch 35/500\n",
      "38/38 - 0s - loss: 0.6311 - accuracy: 0.7381\n",
      "Epoch 36/500\n",
      "38/38 - 0s - loss: 0.6180 - accuracy: 0.7540\n",
      "Epoch 37/500\n",
      "38/38 - 0s - loss: 0.6198 - accuracy: 0.7440\n",
      "Epoch 38/500\n",
      "38/38 - 0s - loss: 0.6096 - accuracy: 0.7515\n",
      "Epoch 39/500\n",
      "38/38 - 0s - loss: 0.6041 - accuracy: 0.7565\n",
      "Epoch 40/500\n",
      "38/38 - 0s - loss: 0.5981 - accuracy: 0.7598\n",
      "Epoch 41/500\n",
      "38/38 - 0s - loss: 0.5859 - accuracy: 0.7715\n",
      "Epoch 42/500\n",
      "38/38 - 0s - loss: 0.5839 - accuracy: 0.7581\n",
      "Epoch 43/500\n",
      "38/38 - 0s - loss: 0.5680 - accuracy: 0.7698\n",
      "Epoch 44/500\n",
      "38/38 - 0s - loss: 0.5759 - accuracy: 0.7656\n",
      "Epoch 45/500\n",
      "38/38 - 0s - loss: 0.5562 - accuracy: 0.7790\n",
      "Epoch 46/500\n",
      "38/38 - 0s - loss: 0.5472 - accuracy: 0.7873\n",
      "Epoch 47/500\n",
      "38/38 - 0s - loss: 0.5568 - accuracy: 0.7832\n",
      "Epoch 48/500\n",
      "38/38 - 0s - loss: 0.5290 - accuracy: 0.7932\n",
      "Epoch 49/500\n",
      "38/38 - 0s - loss: 0.5217 - accuracy: 0.7998\n",
      "Epoch 50/500\n",
      "38/38 - 0s - loss: 0.5237 - accuracy: 0.8015\n",
      "Epoch 51/500\n",
      "38/38 - 0s - loss: 0.5150 - accuracy: 0.7982\n",
      "Epoch 52/500\n",
      "38/38 - 0s - loss: 0.5065 - accuracy: 0.8040\n",
      "Epoch 53/500\n",
      "38/38 - 0s - loss: 0.5029 - accuracy: 0.8090\n",
      "Epoch 54/500\n",
      "38/38 - 0s - loss: 0.4889 - accuracy: 0.8190\n",
      "Epoch 55/500\n",
      "38/38 - 0s - loss: 0.4989 - accuracy: 0.8148\n",
      "Epoch 56/500\n",
      "38/38 - 0s - loss: 0.4873 - accuracy: 0.8107\n",
      "Epoch 57/500\n",
      "38/38 - 0s - loss: 0.4753 - accuracy: 0.8215\n",
      "Epoch 58/500\n",
      "38/38 - 0s - loss: 0.4682 - accuracy: 0.8290\n",
      "Epoch 59/500\n",
      "38/38 - 0s - loss: 0.4635 - accuracy: 0.8307\n",
      "Epoch 60/500\n",
      "38/38 - 0s - loss: 0.4637 - accuracy: 0.8224\n",
      "Epoch 61/500\n",
      "38/38 - 0s - loss: 0.4566 - accuracy: 0.8249\n",
      "Epoch 62/500\n",
      "38/38 - 0s - loss: 0.4646 - accuracy: 0.8324\n",
      "Epoch 63/500\n",
      "38/38 - 0s - loss: 0.4484 - accuracy: 0.8340\n",
      "Epoch 64/500\n",
      "38/38 - 0s - loss: 0.4362 - accuracy: 0.8440\n",
      "Epoch 65/500\n",
      "38/38 - 0s - loss: 0.4260 - accuracy: 0.8474\n",
      "Epoch 66/500\n",
      "38/38 - 0s - loss: 0.4181 - accuracy: 0.8482\n",
      "Epoch 67/500\n",
      "38/38 - 0s - loss: 0.4193 - accuracy: 0.8490\n",
      "Epoch 68/500\n",
      "38/38 - 0s - loss: 0.4086 - accuracy: 0.8532\n",
      "Epoch 69/500\n",
      "38/38 - 0s - loss: 0.4035 - accuracy: 0.8565\n",
      "Epoch 70/500\n",
      "38/38 - 0s - loss: 0.3986 - accuracy: 0.8632\n",
      "Epoch 71/500\n",
      "38/38 - 0s - loss: 0.4012 - accuracy: 0.8599\n",
      "Epoch 72/500\n",
      "38/38 - 0s - loss: 0.3932 - accuracy: 0.8557\n",
      "Epoch 73/500\n",
      "38/38 - 0s - loss: 0.3914 - accuracy: 0.8616\n",
      "Epoch 74/500\n",
      "38/38 - 0s - loss: 0.3795 - accuracy: 0.8666\n",
      "Epoch 75/500\n",
      "38/38 - 0s - loss: 0.3798 - accuracy: 0.8624\n",
      "Epoch 76/500\n",
      "38/38 - 0s - loss: 0.3742 - accuracy: 0.8799\n",
      "Epoch 77/500\n",
      "38/38 - 0s - loss: 0.3651 - accuracy: 0.8741\n",
      "Epoch 78/500\n",
      "38/38 - 0s - loss: 0.3593 - accuracy: 0.8766\n",
      "Epoch 79/500\n",
      "38/38 - 0s - loss: 0.3552 - accuracy: 0.8791\n",
      "Epoch 80/500\n",
      "38/38 - 0s - loss: 0.3549 - accuracy: 0.8816\n",
      "Epoch 81/500\n",
      "38/38 - 0s - loss: 0.3525 - accuracy: 0.8791\n",
      "Epoch 82/500\n",
      "38/38 - 0s - loss: 0.3383 - accuracy: 0.8824\n",
      "Epoch 83/500\n",
      "38/38 - 0s - loss: 0.3481 - accuracy: 0.8799\n",
      "Epoch 84/500\n",
      "38/38 - 0s - loss: 0.3284 - accuracy: 0.8832\n",
      "Epoch 85/500\n",
      "38/38 - 0s - loss: 0.3359 - accuracy: 0.8899\n",
      "Epoch 86/500\n",
      "38/38 - 0s - loss: 0.3159 - accuracy: 0.9024\n",
      "Epoch 87/500\n",
      "38/38 - 0s - loss: 0.3171 - accuracy: 0.8874\n",
      "Epoch 88/500\n",
      "38/38 - 0s - loss: 0.3162 - accuracy: 0.8991\n",
      "Epoch 89/500\n",
      "38/38 - 0s - loss: 0.3129 - accuracy: 0.8941\n",
      "Epoch 90/500\n",
      "38/38 - 0s - loss: 0.3028 - accuracy: 0.9033\n",
      "Epoch 91/500\n",
      "38/38 - 0s - loss: 0.3010 - accuracy: 0.9108\n",
      "Epoch 92/500\n",
      "38/38 - 0s - loss: 0.3043 - accuracy: 0.8932\n",
      "Epoch 93/500\n",
      "38/38 - 0s - loss: 0.3041 - accuracy: 0.8924\n",
      "Epoch 94/500\n",
      "38/38 - 0s - loss: 0.2906 - accuracy: 0.9108\n",
      "Epoch 95/500\n",
      "38/38 - 0s - loss: 0.2924 - accuracy: 0.9016\n",
      "Epoch 96/500\n",
      "38/38 - 0s - loss: 0.2928 - accuracy: 0.9158\n",
      "Epoch 97/500\n",
      "38/38 - 0s - loss: 0.2746 - accuracy: 0.9149\n",
      "Epoch 98/500\n",
      "38/38 - 0s - loss: 0.2784 - accuracy: 0.9091\n",
      "Epoch 99/500\n",
      "38/38 - 0s - loss: 0.2827 - accuracy: 0.9099\n",
      "Epoch 100/500\n",
      "38/38 - 0s - loss: 0.2724 - accuracy: 0.9091\n",
      "Epoch 101/500\n",
      "38/38 - 0s - loss: 0.2632 - accuracy: 0.9174\n",
      "Epoch 102/500\n",
      "38/38 - 0s - loss: 0.2746 - accuracy: 0.9183\n",
      "Epoch 103/500\n",
      "38/38 - 0s - loss: 0.2479 - accuracy: 0.9291\n",
      "Epoch 104/500\n",
      "38/38 - 0s - loss: 0.2467 - accuracy: 0.9299\n",
      "Epoch 105/500\n",
      "38/38 - 0s - loss: 0.2456 - accuracy: 0.9249\n",
      "Epoch 106/500\n",
      "38/38 - 0s - loss: 0.2403 - accuracy: 0.9299\n",
      "Epoch 107/500\n",
      "38/38 - 0s - loss: 0.2386 - accuracy: 0.9324\n",
      "Epoch 108/500\n",
      "38/38 - 0s - loss: 0.2473 - accuracy: 0.9291\n",
      "Epoch 109/500\n",
      "38/38 - 0s - loss: 0.2561 - accuracy: 0.9199\n",
      "Epoch 110/500\n",
      "38/38 - 0s - loss: 0.2332 - accuracy: 0.9324\n",
      "Epoch 111/500\n",
      "38/38 - 0s - loss: 0.2462 - accuracy: 0.9208\n",
      "Epoch 112/500\n",
      "38/38 - 0s - loss: 0.2252 - accuracy: 0.9341\n",
      "Epoch 113/500\n",
      "38/38 - 0s - loss: 0.2191 - accuracy: 0.9408\n",
      "Epoch 114/500\n",
      "38/38 - 0s - loss: 0.2137 - accuracy: 0.9408\n",
      "Epoch 115/500\n",
      "38/38 - 0s - loss: 0.2329 - accuracy: 0.9241\n",
      "Epoch 116/500\n",
      "38/38 - 0s - loss: 0.2317 - accuracy: 0.9224\n",
      "Epoch 117/500\n",
      "38/38 - 0s - loss: 0.2192 - accuracy: 0.9333\n",
      "Epoch 118/500\n",
      "38/38 - 0s - loss: 0.2221 - accuracy: 0.9341\n",
      "Epoch 119/500\n",
      "38/38 - 0s - loss: 0.2098 - accuracy: 0.9349\n",
      "Epoch 120/500\n",
      "38/38 - 0s - loss: 0.2032 - accuracy: 0.9450\n",
      "Epoch 121/500\n",
      "38/38 - 0s - loss: 0.1959 - accuracy: 0.9399\n",
      "Epoch 122/500\n",
      "38/38 - 0s - loss: 0.1987 - accuracy: 0.9391\n",
      "Epoch 123/500\n",
      "38/38 - 0s - loss: 0.1948 - accuracy: 0.9475\n",
      "Epoch 124/500\n",
      "38/38 - 0s - loss: 0.1974 - accuracy: 0.9358\n",
      "Epoch 125/500\n",
      "38/38 - 0s - loss: 0.1811 - accuracy: 0.9500\n",
      "Epoch 126/500\n",
      "38/38 - 0s - loss: 0.1864 - accuracy: 0.9483\n",
      "Epoch 127/500\n",
      "38/38 - 0s - loss: 0.1786 - accuracy: 0.9566\n",
      "Epoch 128/500\n",
      "38/38 - 0s - loss: 0.1767 - accuracy: 0.9583\n",
      "Epoch 129/500\n",
      "38/38 - 0s - loss: 0.1835 - accuracy: 0.9475\n",
      "Epoch 130/500\n",
      "38/38 - 0s - loss: 0.1763 - accuracy: 0.9500\n",
      "Epoch 131/500\n",
      "38/38 - 0s - loss: 0.1949 - accuracy: 0.9383\n",
      "Epoch 132/500\n",
      "38/38 - 0s - loss: 0.1848 - accuracy: 0.9500\n",
      "Epoch 133/500\n",
      "38/38 - 0s - loss: 0.1706 - accuracy: 0.9550\n",
      "Epoch 134/500\n",
      "38/38 - 0s - loss: 0.1715 - accuracy: 0.9550\n",
      "Epoch 135/500\n",
      "38/38 - 0s - loss: 0.1789 - accuracy: 0.9508\n",
      "Epoch 136/500\n",
      "38/38 - 0s - loss: 0.1632 - accuracy: 0.9633\n",
      "Epoch 137/500\n",
      "38/38 - 0s - loss: 0.1512 - accuracy: 0.9650\n",
      "Epoch 138/500\n",
      "38/38 - 0s - loss: 0.1621 - accuracy: 0.9541\n",
      "Epoch 139/500\n",
      "38/38 - 0s - loss: 0.1655 - accuracy: 0.9550\n",
      "Epoch 140/500\n",
      "38/38 - 0s - loss: 0.1511 - accuracy: 0.9675\n",
      "Epoch 141/500\n",
      "38/38 - 0s - loss: 0.1499 - accuracy: 0.9625\n",
      "Epoch 142/500\n",
      "38/38 - 0s - loss: 0.1412 - accuracy: 0.9708\n",
      "Epoch 143/500\n",
      "38/38 - 0s - loss: 0.1482 - accuracy: 0.9641\n",
      "Epoch 144/500\n",
      "38/38 - 0s - loss: 0.1450 - accuracy: 0.9683\n",
      "Epoch 145/500\n",
      "38/38 - 0s - loss: 0.1456 - accuracy: 0.9658\n",
      "Epoch 146/500\n",
      "38/38 - 0s - loss: 0.1349 - accuracy: 0.9658\n",
      "Epoch 147/500\n",
      "38/38 - 0s - loss: 0.1434 - accuracy: 0.9641\n",
      "Epoch 148/500\n",
      "38/38 - 0s - loss: 0.1857 - accuracy: 0.9533\n",
      "Epoch 149/500\n",
      "38/38 - 0s - loss: 0.1563 - accuracy: 0.9616\n",
      "Epoch 150/500\n",
      "38/38 - 0s - loss: 0.1491 - accuracy: 0.9608\n",
      "Epoch 151/500\n",
      "38/38 - 0s - loss: 0.1261 - accuracy: 0.9733\n",
      "Epoch 152/500\n",
      "38/38 - 0s - loss: 0.1346 - accuracy: 0.9725\n",
      "Epoch 153/500\n",
      "38/38 - 0s - loss: 0.1407 - accuracy: 0.9633\n",
      "Epoch 154/500\n",
      "38/38 - 0s - loss: 0.1211 - accuracy: 0.9758\n",
      "Epoch 155/500\n",
      "38/38 - 0s - loss: 0.1177 - accuracy: 0.9750\n",
      "Epoch 156/500\n",
      "38/38 - 0s - loss: 0.1215 - accuracy: 0.9775\n",
      "Epoch 157/500\n",
      "38/38 - 0s - loss: 0.1205 - accuracy: 0.9750\n",
      "Epoch 158/500\n",
      "38/38 - 0s - loss: 0.1116 - accuracy: 0.9766\n",
      "Epoch 159/500\n",
      "38/38 - 0s - loss: 0.1098 - accuracy: 0.9791\n",
      "Epoch 160/500\n",
      "38/38 - 0s - loss: 0.1168 - accuracy: 0.9808\n",
      "Epoch 161/500\n",
      "38/38 - 0s - loss: 0.1133 - accuracy: 0.9741\n",
      "Epoch 162/500\n",
      "38/38 - 0s - loss: 0.1171 - accuracy: 0.9716\n",
      "Epoch 163/500\n",
      "38/38 - 0s - loss: 0.1109 - accuracy: 0.9741\n",
      "Epoch 164/500\n",
      "38/38 - 0s - loss: 0.1107 - accuracy: 0.9791\n",
      "Epoch 165/500\n",
      "38/38 - 0s - loss: 0.1102 - accuracy: 0.9750\n",
      "Epoch 166/500\n",
      "38/38 - 0s - loss: 0.1061 - accuracy: 0.9791\n",
      "Epoch 167/500\n",
      "38/38 - 0s - loss: 0.1085 - accuracy: 0.9791\n",
      "Epoch 168/500\n",
      "38/38 - 0s - loss: 0.1172 - accuracy: 0.9716\n",
      "Epoch 169/500\n",
      "38/38 - 0s - loss: 0.1076 - accuracy: 0.9783\n",
      "Epoch 170/500\n",
      "38/38 - 0s - loss: 0.1233 - accuracy: 0.9783\n",
      "Epoch 171/500\n",
      "38/38 - 0s - loss: 0.1160 - accuracy: 0.9750\n",
      "Epoch 172/500\n",
      "38/38 - 0s - loss: 0.1023 - accuracy: 0.9775\n",
      "Epoch 173/500\n",
      "38/38 - 0s - loss: 0.1269 - accuracy: 0.9700\n",
      "Epoch 174/500\n",
      "38/38 - 0s - loss: 0.1190 - accuracy: 0.9766\n",
      "Epoch 175/500\n",
      "38/38 - 0s - loss: 0.0957 - accuracy: 0.9825\n",
      "Epoch 176/500\n",
      "38/38 - 0s - loss: 0.1098 - accuracy: 0.9750\n",
      "Epoch 177/500\n",
      "38/38 - 0s - loss: 0.1002 - accuracy: 0.9817\n",
      "Epoch 178/500\n",
      "38/38 - 0s - loss: 0.0929 - accuracy: 0.9825\n",
      "Epoch 179/500\n",
      "38/38 - 0s - loss: 0.0893 - accuracy: 0.9850\n",
      "Epoch 180/500\n",
      "38/38 - 0s - loss: 0.0921 - accuracy: 0.9833\n",
      "Epoch 181/500\n",
      "38/38 - 0s - loss: 0.0820 - accuracy: 0.9842\n",
      "Epoch 182/500\n",
      "38/38 - 0s - loss: 0.0914 - accuracy: 0.9808\n",
      "Epoch 183/500\n",
      "38/38 - 0s - loss: 0.0941 - accuracy: 0.9825\n",
      "Epoch 184/500\n",
      "38/38 - 0s - loss: 0.0891 - accuracy: 0.9817\n",
      "Epoch 185/500\n",
      "38/38 - 0s - loss: 0.0883 - accuracy: 0.9833\n",
      "Epoch 186/500\n",
      "38/38 - 0s - loss: 0.0823 - accuracy: 0.9858\n",
      "Epoch 187/500\n",
      "38/38 - 0s - loss: 0.0824 - accuracy: 0.9800\n",
      "Epoch 188/500\n",
      "38/38 - 0s - loss: 0.0835 - accuracy: 0.9842\n",
      "Epoch 189/500\n",
      "38/38 - 0s - loss: 0.0851 - accuracy: 0.9783\n",
      "Epoch 190/500\n",
      "38/38 - 0s - loss: 0.0830 - accuracy: 0.9850\n",
      "Epoch 191/500\n",
      "38/38 - 0s - loss: 0.0762 - accuracy: 0.9833\n",
      "Epoch 192/500\n",
      "38/38 - 0s - loss: 0.0728 - accuracy: 0.9900\n",
      "Epoch 193/500\n",
      "38/38 - 0s - loss: 0.0749 - accuracy: 0.9883\n",
      "Epoch 194/500\n",
      "38/38 - 0s - loss: 0.0728 - accuracy: 0.9892\n",
      "Epoch 195/500\n",
      "38/38 - 0s - loss: 0.0752 - accuracy: 0.9867\n",
      "Epoch 196/500\n",
      "38/38 - 0s - loss: 0.0810 - accuracy: 0.9842\n",
      "Epoch 197/500\n",
      "38/38 - 0s - loss: 0.0711 - accuracy: 0.9875\n",
      "Epoch 198/500\n",
      "38/38 - 0s - loss: 0.0776 - accuracy: 0.9858\n",
      "Epoch 199/500\n",
      "38/38 - 0s - loss: 0.0700 - accuracy: 0.9875\n",
      "Epoch 200/500\n",
      "38/38 - 0s - loss: 0.0746 - accuracy: 0.9842\n",
      "Epoch 201/500\n",
      "38/38 - 0s - loss: 0.0685 - accuracy: 0.9867\n",
      "Epoch 202/500\n",
      "38/38 - 0s - loss: 0.0657 - accuracy: 0.9883\n",
      "Epoch 203/500\n",
      "38/38 - 0s - loss: 0.0694 - accuracy: 0.9842\n",
      "Epoch 204/500\n",
      "38/38 - 0s - loss: 0.0644 - accuracy: 0.9900\n",
      "Epoch 205/500\n",
      "38/38 - 0s - loss: 0.0617 - accuracy: 0.9892\n",
      "Epoch 206/500\n",
      "38/38 - 0s - loss: 0.0668 - accuracy: 0.9892\n",
      "Epoch 207/500\n",
      "38/38 - 0s - loss: 0.0646 - accuracy: 0.9892\n",
      "Epoch 208/500\n",
      "38/38 - 0s - loss: 0.0628 - accuracy: 0.9875\n",
      "Epoch 209/500\n",
      "38/38 - 0s - loss: 0.0728 - accuracy: 0.9867\n",
      "Epoch 210/500\n",
      "38/38 - 0s - loss: 0.0717 - accuracy: 0.9833\n",
      "Epoch 211/500\n",
      "38/38 - 0s - loss: 0.0698 - accuracy: 0.9875\n",
      "Epoch 212/500\n",
      "38/38 - 0s - loss: 0.0615 - accuracy: 0.9892\n",
      "Epoch 213/500\n",
      "38/38 - 0s - loss: 0.0568 - accuracy: 0.9900\n",
      "Epoch 214/500\n",
      "38/38 - 0s - loss: 0.0612 - accuracy: 0.9933\n",
      "Epoch 215/500\n",
      "38/38 - 0s - loss: 0.0606 - accuracy: 0.9900\n",
      "Epoch 216/500\n",
      "38/38 - 0s - loss: 0.0591 - accuracy: 0.9883\n",
      "Epoch 217/500\n",
      "38/38 - 0s - loss: 0.0656 - accuracy: 0.9867\n",
      "Epoch 218/500\n",
      "38/38 - 0s - loss: 0.0596 - accuracy: 0.9883\n",
      "Epoch 219/500\n",
      "38/38 - 0s - loss: 0.0590 - accuracy: 0.9892\n",
      "Epoch 220/500\n",
      "38/38 - 0s - loss: 0.0997 - accuracy: 0.9775\n",
      "Epoch 221/500\n",
      "38/38 - 0s - loss: 0.1014 - accuracy: 0.9750\n",
      "Epoch 222/500\n",
      "38/38 - 0s - loss: 0.0595 - accuracy: 0.9900\n",
      "Epoch 223/500\n",
      "38/38 - 0s - loss: 0.0536 - accuracy: 0.9917\n",
      "Epoch 224/500\n",
      "38/38 - 0s - loss: 0.0538 - accuracy: 0.9900\n",
      "Epoch 225/500\n",
      "38/38 - 0s - loss: 0.0542 - accuracy: 0.9908\n",
      "Epoch 226/500\n",
      "38/38 - 0s - loss: 0.0468 - accuracy: 0.9917\n",
      "Epoch 227/500\n",
      "38/38 - 0s - loss: 0.0504 - accuracy: 0.9933\n",
      "Epoch 228/500\n",
      "38/38 - 0s - loss: 0.0434 - accuracy: 0.9933\n",
      "Epoch 229/500\n",
      "38/38 - 0s - loss: 0.0445 - accuracy: 0.9917\n",
      "Epoch 230/500\n",
      "38/38 - 0s - loss: 0.0481 - accuracy: 0.9917\n",
      "Epoch 231/500\n",
      "38/38 - 0s - loss: 0.0497 - accuracy: 0.9917\n",
      "Epoch 232/500\n",
      "38/38 - 0s - loss: 0.0573 - accuracy: 0.9892\n",
      "Epoch 233/500\n",
      "38/38 - 0s - loss: 0.0565 - accuracy: 0.9883\n",
      "Epoch 234/500\n",
      "38/38 - 0s - loss: 0.0524 - accuracy: 0.9908\n",
      "Epoch 235/500\n",
      "38/38 - 0s - loss: 0.0509 - accuracy: 0.9908\n",
      "Epoch 236/500\n",
      "38/38 - 0s - loss: 0.0661 - accuracy: 0.9783\n",
      "Epoch 237/500\n",
      "38/38 - 0s - loss: 0.0579 - accuracy: 0.9900\n",
      "Epoch 238/500\n",
      "38/38 - 0s - loss: 0.0463 - accuracy: 0.9917\n",
      "Epoch 239/500\n",
      "38/38 - 0s - loss: 0.0460 - accuracy: 0.9925\n",
      "Epoch 240/500\n",
      "38/38 - 0s - loss: 0.0497 - accuracy: 0.9917\n",
      "Epoch 241/500\n",
      "38/38 - 0s - loss: 0.0572 - accuracy: 0.9908\n",
      "Epoch 242/500\n",
      "38/38 - 0s - loss: 0.0457 - accuracy: 0.9900\n",
      "Epoch 243/500\n",
      "38/38 - 0s - loss: 0.0403 - accuracy: 0.9917\n",
      "Epoch 244/500\n",
      "38/38 - 0s - loss: 0.0443 - accuracy: 0.9925\n",
      "Epoch 245/500\n",
      "38/38 - 0s - loss: 0.0446 - accuracy: 0.9917\n",
      "Epoch 246/500\n",
      "38/38 - 0s - loss: 0.0433 - accuracy: 0.9942\n",
      "Epoch 247/500\n",
      "38/38 - 0s - loss: 0.0453 - accuracy: 0.9908\n",
      "Epoch 248/500\n",
      "38/38 - 0s - loss: 0.0474 - accuracy: 0.9933\n",
      "Epoch 249/500\n",
      "38/38 - 0s - loss: 0.0426 - accuracy: 0.9892\n",
      "Epoch 250/500\n",
      "38/38 - 0s - loss: 0.0415 - accuracy: 0.9933\n",
      "Epoch 251/500\n",
      "38/38 - 0s - loss: 0.0422 - accuracy: 0.9917\n",
      "Epoch 252/500\n",
      "38/38 - 0s - loss: 0.0454 - accuracy: 0.9925\n",
      "Epoch 253/500\n",
      "38/38 - 0s - loss: 0.0430 - accuracy: 0.9942\n",
      "Epoch 254/500\n",
      "38/38 - 0s - loss: 0.0368 - accuracy: 0.9917\n",
      "Epoch 255/500\n",
      "38/38 - 0s - loss: 0.0374 - accuracy: 0.9925\n",
      "Epoch 256/500\n",
      "38/38 - 0s - loss: 0.0408 - accuracy: 0.9925\n",
      "Epoch 257/500\n",
      "38/38 - 0s - loss: 0.0392 - accuracy: 0.9925\n",
      "Epoch 258/500\n",
      "38/38 - 0s - loss: 0.0411 - accuracy: 0.9917\n",
      "Epoch 259/500\n",
      "38/38 - 0s - loss: 0.0351 - accuracy: 0.9950\n",
      "Epoch 260/500\n",
      "38/38 - 0s - loss: 0.0339 - accuracy: 0.9917\n",
      "Epoch 261/500\n",
      "38/38 - 0s - loss: 0.0357 - accuracy: 0.9942\n",
      "Epoch 262/500\n",
      "38/38 - 0s - loss: 0.0345 - accuracy: 0.9933\n",
      "Epoch 263/500\n",
      "38/38 - 0s - loss: 0.0381 - accuracy: 0.9942\n",
      "Epoch 264/500\n",
      "38/38 - 0s - loss: 0.0392 - accuracy: 0.9917\n",
      "Epoch 265/500\n",
      "38/38 - 0s - loss: 0.0333 - accuracy: 0.9933\n",
      "Epoch 266/500\n",
      "38/38 - 0s - loss: 0.0340 - accuracy: 0.9967\n",
      "Epoch 267/500\n",
      "38/38 - 0s - loss: 0.0325 - accuracy: 0.9900\n",
      "Epoch 268/500\n",
      "38/38 - 0s - loss: 0.0347 - accuracy: 0.9917\n",
      "Epoch 269/500\n",
      "38/38 - 0s - loss: 0.0320 - accuracy: 0.9925\n",
      "Epoch 270/500\n",
      "38/38 - 0s - loss: 0.0358 - accuracy: 0.9933\n",
      "Epoch 271/500\n",
      "38/38 - 0s - loss: 0.0357 - accuracy: 0.9917\n",
      "Epoch 272/500\n",
      "38/38 - 0s - loss: 0.0344 - accuracy: 0.9942\n",
      "Epoch 273/500\n",
      "38/38 - 0s - loss: 0.0311 - accuracy: 0.9933\n",
      "Epoch 274/500\n",
      "38/38 - 0s - loss: 0.0359 - accuracy: 0.9925\n",
      "Epoch 275/500\n",
      "38/38 - 0s - loss: 0.0341 - accuracy: 0.9933\n",
      "Epoch 276/500\n",
      "38/38 - 0s - loss: 0.0354 - accuracy: 0.9942\n",
      "Epoch 277/500\n",
      "38/38 - 0s - loss: 0.0386 - accuracy: 0.9908\n",
      "Epoch 278/500\n",
      "38/38 - 0s - loss: 0.0762 - accuracy: 0.9800\n",
      "Epoch 279/500\n",
      "38/38 - 0s - loss: 0.1410 - accuracy: 0.9600\n",
      "Epoch 280/500\n",
      "38/38 - 0s - loss: 0.1866 - accuracy: 0.9491\n",
      "Epoch 281/500\n",
      "38/38 - 0s - loss: 0.0877 - accuracy: 0.9700\n",
      "Epoch 282/500\n",
      "38/38 - 0s - loss: 0.0454 - accuracy: 0.9917\n",
      "Epoch 283/500\n",
      "38/38 - 0s - loss: 0.0360 - accuracy: 0.9892\n",
      "Epoch 284/500\n",
      "38/38 - 0s - loss: 0.0273 - accuracy: 0.9942\n",
      "Epoch 285/500\n",
      "38/38 - 0s - loss: 0.0262 - accuracy: 0.9967\n",
      "Epoch 286/500\n",
      "38/38 - 0s - loss: 0.0263 - accuracy: 0.9942\n",
      "Epoch 287/500\n",
      "38/38 - 0s - loss: 0.0273 - accuracy: 0.9933\n",
      "Epoch 288/500\n",
      "38/38 - 0s - loss: 0.0271 - accuracy: 0.9967\n",
      "Epoch 289/500\n",
      "38/38 - 0s - loss: 0.0268 - accuracy: 0.9942\n",
      "Epoch 290/500\n",
      "38/38 - 0s - loss: 0.0289 - accuracy: 0.9933\n",
      "Epoch 291/500\n",
      "38/38 - 0s - loss: 0.0272 - accuracy: 0.9933\n",
      "Epoch 292/500\n",
      "38/38 - 0s - loss: 0.0304 - accuracy: 0.9933\n",
      "Epoch 293/500\n",
      "38/38 - 0s - loss: 0.0264 - accuracy: 0.9925\n",
      "Epoch 294/500\n",
      "38/38 - 0s - loss: 0.0253 - accuracy: 0.9967\n",
      "Epoch 295/500\n",
      "38/38 - 0s - loss: 0.0219 - accuracy: 0.9958\n",
      "Epoch 296/500\n",
      "38/38 - 0s - loss: 0.0303 - accuracy: 0.9917\n",
      "Epoch 297/500\n",
      "38/38 - 0s - loss: 0.0262 - accuracy: 0.9967\n",
      "Epoch 298/500\n",
      "38/38 - 0s - loss: 0.0278 - accuracy: 0.9942\n",
      "Epoch 299/500\n",
      "38/38 - 0s - loss: 0.0365 - accuracy: 0.9892\n",
      "Epoch 300/500\n",
      "38/38 - 0s - loss: 0.0263 - accuracy: 0.9958\n",
      "Epoch 301/500\n",
      "38/38 - 0s - loss: 0.0344 - accuracy: 0.9942\n",
      "Epoch 302/500\n",
      "38/38 - 0s - loss: 0.0340 - accuracy: 0.9933\n",
      "Epoch 303/500\n",
      "38/38 - 0s - loss: 0.0260 - accuracy: 0.9942\n",
      "Epoch 304/500\n",
      "38/38 - 0s - loss: 0.0336 - accuracy: 0.9925\n",
      "Epoch 305/500\n",
      "38/38 - 0s - loss: 0.0240 - accuracy: 0.9967\n",
      "Epoch 306/500\n",
      "38/38 - 0s - loss: 0.0272 - accuracy: 0.9950\n",
      "Epoch 307/500\n",
      "38/38 - 0s - loss: 0.0446 - accuracy: 0.9942\n",
      "Epoch 308/500\n",
      "38/38 - 0s - loss: 0.0495 - accuracy: 0.9900\n",
      "Epoch 309/500\n",
      "38/38 - 0s - loss: 0.0401 - accuracy: 0.9917\n",
      "Epoch 310/500\n",
      "38/38 - 0s - loss: 0.0321 - accuracy: 0.9917\n",
      "Epoch 311/500\n",
      "38/38 - 0s - loss: 0.0240 - accuracy: 0.9967\n",
      "Epoch 312/500\n",
      "38/38 - 0s - loss: 0.0250 - accuracy: 0.9958\n",
      "Epoch 313/500\n",
      "38/38 - 0s - loss: 0.0240 - accuracy: 0.9958\n",
      "Epoch 314/500\n",
      "38/38 - 0s - loss: 0.0271 - accuracy: 0.9917\n",
      "Epoch 315/500\n",
      "38/38 - 0s - loss: 0.0278 - accuracy: 0.9942\n",
      "Epoch 316/500\n",
      "38/38 - 0s - loss: 0.0270 - accuracy: 0.9958\n",
      "Epoch 317/500\n",
      "38/38 - 0s - loss: 0.0250 - accuracy: 0.9933\n",
      "Epoch 318/500\n",
      "38/38 - 0s - loss: 0.0290 - accuracy: 0.9967\n",
      "Epoch 319/500\n",
      "38/38 - 0s - loss: 0.0211 - accuracy: 0.9950\n",
      "Epoch 320/500\n",
      "38/38 - 0s - loss: 0.0285 - accuracy: 0.9925\n",
      "Epoch 321/500\n",
      "38/38 - 0s - loss: 0.0274 - accuracy: 0.9933\n",
      "Epoch 322/500\n",
      "38/38 - 0s - loss: 0.0263 - accuracy: 0.9950\n",
      "Epoch 323/500\n",
      "38/38 - 0s - loss: 0.0190 - accuracy: 0.9950\n",
      "Epoch 324/500\n",
      "38/38 - 0s - loss: 0.0242 - accuracy: 0.9950\n",
      "Epoch 325/500\n",
      "38/38 - 0s - loss: 0.0286 - accuracy: 0.9942\n",
      "Epoch 326/500\n",
      "38/38 - 0s - loss: 0.0341 - accuracy: 0.9917\n",
      "Epoch 327/500\n",
      "38/38 - 0s - loss: 0.0333 - accuracy: 0.9917\n",
      "Epoch 328/500\n",
      "38/38 - 0s - loss: 0.0260 - accuracy: 0.9958\n",
      "Epoch 329/500\n",
      "38/38 - 0s - loss: 0.0365 - accuracy: 0.9900\n",
      "Epoch 330/500\n",
      "38/38 - 0s - loss: 0.0387 - accuracy: 0.9933\n",
      "Epoch 331/500\n",
      "38/38 - 0s - loss: 0.0329 - accuracy: 0.9925\n",
      "Epoch 332/500\n",
      "38/38 - 0s - loss: 0.0343 - accuracy: 0.9925\n",
      "Epoch 333/500\n",
      "38/38 - 0s - loss: 0.0476 - accuracy: 0.9867\n",
      "Epoch 334/500\n",
      "38/38 - 0s - loss: 0.0281 - accuracy: 0.9900\n",
      "Epoch 335/500\n",
      "38/38 - 0s - loss: 0.0692 - accuracy: 0.9758\n",
      "Epoch 336/500\n",
      "38/38 - 0s - loss: 0.0423 - accuracy: 0.9892\n",
      "Epoch 337/500\n",
      "38/38 - 0s - loss: 0.0248 - accuracy: 0.9967\n",
      "Epoch 338/500\n",
      "38/38 - 0s - loss: 0.0195 - accuracy: 0.9958\n",
      "Epoch 339/500\n",
      "38/38 - 0s - loss: 0.0183 - accuracy: 0.9958\n",
      "Epoch 340/500\n",
      "38/38 - 0s - loss: 0.0177 - accuracy: 0.9967\n",
      "Epoch 341/500\n",
      "38/38 - 0s - loss: 0.0215 - accuracy: 0.9958\n",
      "Epoch 342/500\n",
      "38/38 - 0s - loss: 0.0254 - accuracy: 0.9942\n",
      "Epoch 343/500\n",
      "38/38 - 0s - loss: 0.0278 - accuracy: 0.9925\n",
      "Epoch 344/500\n",
      "38/38 - 0s - loss: 0.0252 - accuracy: 0.9942\n",
      "Epoch 345/500\n",
      "38/38 - 0s - loss: 0.0224 - accuracy: 0.9933\n",
      "Epoch 346/500\n",
      "38/38 - 0s - loss: 0.0204 - accuracy: 0.9967\n",
      "Epoch 347/500\n",
      "38/38 - 0s - loss: 0.0226 - accuracy: 0.9950\n",
      "Epoch 348/500\n",
      "38/38 - 0s - loss: 0.0153 - accuracy: 0.9975\n",
      "Epoch 349/500\n",
      "38/38 - 0s - loss: 0.0192 - accuracy: 0.9958\n",
      "Epoch 350/500\n",
      "38/38 - 0s - loss: 0.0202 - accuracy: 0.9967\n",
      "Epoch 351/500\n",
      "38/38 - 0s - loss: 0.0167 - accuracy: 0.9967\n",
      "Epoch 352/500\n",
      "38/38 - 0s - loss: 0.0180 - accuracy: 0.9975\n",
      "Epoch 353/500\n",
      "38/38 - 0s - loss: 0.0372 - accuracy: 0.9925\n",
      "Epoch 354/500\n",
      "38/38 - 0s - loss: 0.0271 - accuracy: 0.9933\n",
      "Epoch 355/500\n",
      "38/38 - 0s - loss: 0.0285 - accuracy: 0.9942\n",
      "Epoch 356/500\n",
      "38/38 - 0s - loss: 0.0269 - accuracy: 0.9950\n",
      "Epoch 357/500\n",
      "38/38 - 0s - loss: 0.0262 - accuracy: 0.9933\n",
      "Epoch 358/500\n",
      "38/38 - 0s - loss: 0.0225 - accuracy: 0.9917\n",
      "Epoch 359/500\n",
      "38/38 - 0s - loss: 0.0252 - accuracy: 0.9950\n",
      "Epoch 360/500\n",
      "38/38 - 0s - loss: 0.0272 - accuracy: 0.9950\n",
      "Epoch 361/500\n",
      "38/38 - 0s - loss: 0.0369 - accuracy: 0.9908\n",
      "Epoch 362/500\n",
      "38/38 - 0s - loss: 0.0198 - accuracy: 0.9975\n",
      "Epoch 363/500\n",
      "38/38 - 0s - loss: 0.0170 - accuracy: 0.9975\n",
      "Epoch 364/500\n",
      "38/38 - 0s - loss: 0.0219 - accuracy: 0.9942\n",
      "Epoch 365/500\n",
      "38/38 - 0s - loss: 0.0193 - accuracy: 0.9958\n",
      "Epoch 366/500\n",
      "38/38 - 0s - loss: 0.0180 - accuracy: 0.9958\n",
      "Epoch 367/500\n",
      "38/38 - 0s - loss: 0.0256 - accuracy: 0.9950\n",
      "Epoch 368/500\n",
      "38/38 - 0s - loss: 0.0167 - accuracy: 0.9958\n",
      "Epoch 369/500\n",
      "38/38 - 0s - loss: 0.0178 - accuracy: 0.9958\n",
      "Epoch 370/500\n",
      "38/38 - 0s - loss: 0.0262 - accuracy: 0.9942\n",
      "Epoch 371/500\n",
      "38/38 - 0s - loss: 0.0222 - accuracy: 0.9950\n",
      "Epoch 372/500\n",
      "38/38 - 0s - loss: 0.0150 - accuracy: 0.9950\n",
      "Epoch 373/500\n",
      "38/38 - 0s - loss: 0.0152 - accuracy: 0.9967\n",
      "Epoch 374/500\n",
      "38/38 - 0s - loss: 0.0143 - accuracy: 0.9967\n",
      "Epoch 375/500\n",
      "38/38 - 0s - loss: 0.0229 - accuracy: 0.9942\n",
      "Epoch 376/500\n",
      "38/38 - 0s - loss: 0.0290 - accuracy: 0.9975\n",
      "Epoch 377/500\n",
      "38/38 - 0s - loss: 0.0254 - accuracy: 0.9950\n",
      "Epoch 378/500\n",
      "38/38 - 0s - loss: 0.0181 - accuracy: 0.9958\n",
      "Epoch 379/500\n",
      "38/38 - 0s - loss: 0.0184 - accuracy: 0.9958\n",
      "Epoch 380/500\n",
      "38/38 - 0s - loss: 0.0165 - accuracy: 0.9967\n",
      "Epoch 381/500\n",
      "38/38 - 0s - loss: 0.0161 - accuracy: 0.9958\n",
      "Epoch 382/500\n",
      "38/38 - 0s - loss: 0.0189 - accuracy: 0.9942\n",
      "Epoch 383/500\n",
      "38/38 - 0s - loss: 0.0260 - accuracy: 0.9925\n",
      "Epoch 384/500\n",
      "38/38 - 0s - loss: 0.0237 - accuracy: 0.9933\n",
      "Epoch 385/500\n",
      "38/38 - 0s - loss: 0.0251 - accuracy: 0.9950\n",
      "Epoch 386/500\n",
      "38/38 - 0s - loss: 0.0259 - accuracy: 0.9925\n",
      "Epoch 387/500\n",
      "38/38 - 0s - loss: 0.0309 - accuracy: 0.9925\n",
      "Epoch 388/500\n",
      "38/38 - 0s - loss: 0.0658 - accuracy: 0.9825\n",
      "Epoch 389/500\n",
      "38/38 - 0s - loss: 0.0303 - accuracy: 0.9933\n",
      "Epoch 390/500\n",
      "38/38 - 0s - loss: 0.0164 - accuracy: 0.9942\n",
      "Epoch 391/500\n",
      "38/38 - 0s - loss: 0.0320 - accuracy: 0.9942\n",
      "Epoch 392/500\n",
      "38/38 - 0s - loss: 0.1269 - accuracy: 0.9625\n",
      "Epoch 393/500\n",
      "38/38 - 0s - loss: 0.1183 - accuracy: 0.9641\n",
      "Epoch 394/500\n",
      "38/38 - 0s - loss: 0.0886 - accuracy: 0.9658\n",
      "Epoch 395/500\n",
      "38/38 - 0s - loss: 0.0335 - accuracy: 0.9908\n",
      "Epoch 396/500\n",
      "38/38 - 0s - loss: 0.0514 - accuracy: 0.9925\n",
      "Epoch 397/500\n",
      "38/38 - 0s - loss: 0.0317 - accuracy: 0.9950\n",
      "Epoch 398/500\n",
      "38/38 - 0s - loss: 0.0136 - accuracy: 0.9967\n",
      "Epoch 399/500\n",
      "38/38 - 0s - loss: 0.0200 - accuracy: 0.9942\n",
      "Epoch 400/500\n",
      "38/38 - 0s - loss: 0.0421 - accuracy: 0.9917\n",
      "Epoch 401/500\n",
      "38/38 - 0s - loss: 0.0632 - accuracy: 0.9925\n",
      "Epoch 402/500\n",
      "38/38 - 0s - loss: 0.0160 - accuracy: 0.9975\n",
      "Epoch 403/500\n",
      "38/38 - 0s - loss: 0.0144 - accuracy: 0.9967\n",
      "Epoch 404/500\n",
      "38/38 - 0s - loss: 0.0125 - accuracy: 0.9975\n",
      "Epoch 405/500\n",
      "38/38 - 0s - loss: 0.0158 - accuracy: 0.9983\n",
      "Epoch 406/500\n",
      "38/38 - 0s - loss: 0.0168 - accuracy: 0.9958\n",
      "Epoch 407/500\n",
      "38/38 - 0s - loss: 0.0177 - accuracy: 0.9983\n",
      "Epoch 408/500\n",
      "38/38 - 0s - loss: 0.0103 - accuracy: 0.9992\n",
      "Epoch 409/500\n",
      "38/38 - 0s - loss: 0.0156 - accuracy: 0.9975\n",
      "Epoch 410/500\n",
      "38/38 - 0s - loss: 0.0161 - accuracy: 0.9983\n",
      "Epoch 411/500\n",
      "38/38 - 0s - loss: 0.0126 - accuracy: 0.9967\n",
      "Epoch 412/500\n",
      "38/38 - 0s - loss: 0.0190 - accuracy: 0.9967\n",
      "Epoch 413/500\n",
      "38/38 - 0s - loss: 0.0209 - accuracy: 0.9967\n",
      "Epoch 414/500\n",
      "38/38 - 0s - loss: 0.0132 - accuracy: 0.9967\n",
      "Epoch 415/500\n",
      "38/38 - 0s - loss: 0.0163 - accuracy: 0.9975\n",
      "Epoch 416/500\n",
      "38/38 - 0s - loss: 0.0187 - accuracy: 0.9950\n",
      "Epoch 417/500\n",
      "38/38 - 0s - loss: 0.0169 - accuracy: 0.9958\n",
      "Epoch 418/500\n",
      "38/38 - 0s - loss: 0.0196 - accuracy: 0.9933\n",
      "Epoch 419/500\n",
      "38/38 - 0s - loss: 0.0189 - accuracy: 0.9958\n",
      "Epoch 420/500\n",
      "38/38 - 0s - loss: 0.0199 - accuracy: 0.9950\n",
      "Epoch 421/500\n",
      "38/38 - 0s - loss: 0.0179 - accuracy: 0.9967\n",
      "Epoch 422/500\n",
      "38/38 - 0s - loss: 0.0157 - accuracy: 0.9975\n",
      "Epoch 423/500\n",
      "38/38 - 0s - loss: 0.0164 - accuracy: 0.9950\n",
      "Epoch 424/500\n",
      "38/38 - 0s - loss: 0.0207 - accuracy: 0.9950\n",
      "Epoch 425/500\n",
      "38/38 - 0s - loss: 0.0185 - accuracy: 0.9958\n",
      "Epoch 426/500\n",
      "38/38 - 0s - loss: 0.0236 - accuracy: 0.9950\n",
      "Epoch 427/500\n",
      "38/38 - 0s - loss: 0.0291 - accuracy: 0.9950\n",
      "Epoch 428/500\n",
      "38/38 - 0s - loss: 0.0130 - accuracy: 0.9958\n",
      "Epoch 429/500\n",
      "38/38 - 0s - loss: 0.0154 - accuracy: 0.9983\n",
      "Epoch 430/500\n",
      "38/38 - 0s - loss: 0.0164 - accuracy: 0.9942\n",
      "Epoch 431/500\n",
      "38/38 - 0s - loss: 0.0173 - accuracy: 0.9983\n",
      "Epoch 432/500\n",
      "38/38 - 0s - loss: 0.0320 - accuracy: 0.9942\n",
      "Epoch 433/500\n",
      "38/38 - 0s - loss: 0.0213 - accuracy: 0.9950\n",
      "Epoch 434/500\n",
      "38/38 - 0s - loss: 0.0133 - accuracy: 0.9983\n",
      "Epoch 435/500\n",
      "38/38 - 0s - loss: 0.0172 - accuracy: 0.9967\n",
      "Epoch 436/500\n",
      "38/38 - 0s - loss: 0.0160 - accuracy: 0.9967\n",
      "Epoch 437/500\n",
      "38/38 - 0s - loss: 0.0219 - accuracy: 0.9967\n",
      "Epoch 438/500\n",
      "38/38 - 0s - loss: 0.0104 - accuracy: 0.9967\n",
      "Epoch 439/500\n",
      "38/38 - 0s - loss: 0.0158 - accuracy: 0.9950\n",
      "Epoch 440/500\n",
      "38/38 - 0s - loss: 0.0141 - accuracy: 0.9967\n",
      "Epoch 441/500\n",
      "38/38 - 0s - loss: 0.0122 - accuracy: 0.9975\n",
      "Epoch 442/500\n",
      "38/38 - 0s - loss: 0.0176 - accuracy: 0.9967\n",
      "Epoch 443/500\n",
      "38/38 - 0s - loss: 0.0120 - accuracy: 0.9983\n",
      "Epoch 444/500\n",
      "38/38 - 0s - loss: 0.0110 - accuracy: 0.9983\n",
      "Epoch 445/500\n",
      "38/38 - 0s - loss: 0.0105 - accuracy: 0.9983\n",
      "Epoch 446/500\n",
      "38/38 - 0s - loss: 0.0124 - accuracy: 0.9967\n",
      "Epoch 447/500\n",
      "38/38 - 0s - loss: 0.0168 - accuracy: 0.9942\n",
      "Epoch 448/500\n",
      "38/38 - 0s - loss: 0.0135 - accuracy: 0.9975\n",
      "Epoch 449/500\n",
      "38/38 - 0s - loss: 0.0156 - accuracy: 0.9967\n",
      "Epoch 450/500\n",
      "38/38 - 0s - loss: 0.0311 - accuracy: 0.9958\n",
      "Epoch 451/500\n",
      "38/38 - 0s - loss: 0.0192 - accuracy: 0.9950\n",
      "Epoch 452/500\n",
      "38/38 - 0s - loss: 0.0266 - accuracy: 0.9933\n",
      "Epoch 453/500\n",
      "38/38 - 0s - loss: 0.0224 - accuracy: 0.9933\n",
      "Epoch 454/500\n",
      "38/38 - 0s - loss: 0.0168 - accuracy: 0.9942\n",
      "Epoch 455/500\n",
      "38/38 - 0s - loss: 0.0236 - accuracy: 0.9950\n",
      "Epoch 456/500\n",
      "38/38 - 0s - loss: 0.0222 - accuracy: 0.9950\n",
      "Epoch 457/500\n",
      "38/38 - 0s - loss: 0.0515 - accuracy: 0.9875\n",
      "Epoch 458/500\n",
      "38/38 - 0s - loss: 0.1218 - accuracy: 0.9683\n",
      "Epoch 459/500\n",
      "38/38 - 0s - loss: 0.0535 - accuracy: 0.9833\n",
      "Epoch 460/500\n",
      "38/38 - 0s - loss: 0.0201 - accuracy: 0.9967\n",
      "Epoch 461/500\n",
      "38/38 - 0s - loss: 0.0099 - accuracy: 0.9983\n",
      "Epoch 462/500\n",
      "38/38 - 0s - loss: 0.0113 - accuracy: 0.9975\n",
      "Epoch 463/500\n",
      "38/38 - 0s - loss: 0.0144 - accuracy: 0.9975\n",
      "Epoch 464/500\n",
      "38/38 - 0s - loss: 0.0129 - accuracy: 0.9975\n",
      "Epoch 465/500\n",
      "38/38 - 0s - loss: 0.0131 - accuracy: 0.9967\n",
      "Epoch 466/500\n",
      "38/38 - 0s - loss: 0.0114 - accuracy: 0.9975\n",
      "Epoch 467/500\n",
      "38/38 - 0s - loss: 0.0172 - accuracy: 0.9958\n",
      "Epoch 468/500\n",
      "38/38 - 0s - loss: 0.0103 - accuracy: 0.9958\n",
      "Epoch 469/500\n",
      "38/38 - 0s - loss: 0.0088 - accuracy: 0.9967\n",
      "Epoch 470/500\n",
      "38/38 - 0s - loss: 0.0107 - accuracy: 0.9983\n",
      "Epoch 471/500\n",
      "38/38 - 0s - loss: 0.0127 - accuracy: 0.9975\n",
      "Epoch 472/500\n",
      "38/38 - 0s - loss: 0.0087 - accuracy: 0.9975\n",
      "Epoch 473/500\n",
      "38/38 - 0s - loss: 0.0145 - accuracy: 0.9967\n",
      "Epoch 474/500\n",
      "38/38 - 0s - loss: 0.0130 - accuracy: 0.9967\n",
      "Epoch 475/500\n",
      "38/38 - 0s - loss: 0.0152 - accuracy: 0.9958\n",
      "Epoch 476/500\n",
      "38/38 - 0s - loss: 0.0112 - accuracy: 0.9967\n",
      "Epoch 477/500\n",
      "38/38 - 0s - loss: 0.0097 - accuracy: 0.9975\n",
      "Epoch 478/500\n",
      "38/38 - 0s - loss: 0.0089 - accuracy: 0.9967\n",
      "Epoch 479/500\n",
      "38/38 - 0s - loss: 0.0082 - accuracy: 0.9975\n",
      "Epoch 480/500\n",
      "38/38 - 0s - loss: 0.0137 - accuracy: 0.9967\n",
      "Epoch 481/500\n",
      "38/38 - 0s - loss: 0.0105 - accuracy: 0.9975\n",
      "Epoch 482/500\n",
      "38/38 - 0s - loss: 0.0117 - accuracy: 0.9975\n",
      "Epoch 483/500\n",
      "38/38 - 0s - loss: 0.0105 - accuracy: 0.9975\n",
      "Epoch 484/500\n",
      "38/38 - 0s - loss: 0.0089 - accuracy: 0.9983\n",
      "Epoch 485/500\n",
      "38/38 - 0s - loss: 0.0118 - accuracy: 0.9975\n",
      "Epoch 486/500\n",
      "38/38 - 0s - loss: 0.0087 - accuracy: 0.9983\n",
      "Epoch 487/500\n",
      "38/38 - 0s - loss: 0.0159 - accuracy: 0.9975\n",
      "Epoch 488/500\n",
      "38/38 - 0s - loss: 0.0224 - accuracy: 0.9950\n",
      "Epoch 489/500\n",
      "38/38 - 0s - loss: 0.0204 - accuracy: 0.9958\n",
      "Epoch 490/500\n",
      "38/38 - 0s - loss: 0.0419 - accuracy: 0.9933\n",
      "Epoch 491/500\n",
      "38/38 - 0s - loss: 0.0137 - accuracy: 0.9958\n",
      "Epoch 492/500\n",
      "38/38 - 0s - loss: 0.0197 - accuracy: 0.9908\n",
      "Epoch 493/500\n",
      "38/38 - 0s - loss: 0.0155 - accuracy: 0.9933\n",
      "Epoch 494/500\n",
      "38/38 - 0s - loss: 0.0147 - accuracy: 0.9967\n",
      "Epoch 495/500\n",
      "38/38 - 0s - loss: 0.0123 - accuracy: 0.9967\n",
      "Epoch 496/500\n",
      "38/38 - 0s - loss: 0.0102 - accuracy: 0.9992\n",
      "Epoch 497/500\n",
      "38/38 - 0s - loss: 0.0087 - accuracy: 0.9967\n",
      "Epoch 498/500\n",
      "38/38 - 0s - loss: 0.0108 - accuracy: 0.9958\n",
      "Epoch 499/500\n",
      "38/38 - 0s - loss: 0.0124 - accuracy: 0.9975\n",
      "Epoch 500/500\n",
      "38/38 - 0s - loss: 0.0121 - accuracy: 0.9950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b127a8db88>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the neural network model to the training data\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=500,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prediction function \n",
    "def predict(model, X_scaler, y_scaler, user_inputs):\n",
    "    # get the user input data \n",
    "    fixed_acidity = user_inputs[\"fixed acidity\"]\n",
    "    volatile_acidity = user_inputs[\"volatile acidity\"]\n",
    "    citric_acid = user_inputs[\"citric acid\"]\n",
    "    residual_sugar = user_inputs[\"residual sugar\"]\n",
    "    chlorides = user_inputs[\"chlorides\"]\n",
    "    free_sulfur_dioxide = user_inputs[\"free sulfur dioxide\"]\n",
    "    total_sulfur_dioxide = user_inputs[\"total sulfur dioxide\"]\n",
    "    density = user_inputs[\"density\"]\n",
    "    pH = user_inputs[\"pH\"]\n",
    "    sulphates = user_inputs[\"sulphates\"]\n",
    "    alcohol = user_inputs[\"alcohol\"]\n",
    "\n",
    "    # store input data into df \n",
    "    input_df = pd.DataFrame({\n",
    "        \"fixed_acidity\": [fixed_acidity],\n",
    "        \"volatile_acidity\": [volatile_acidity],\n",
    "        \"citric_acid\": [citric_acid],\n",
    "        \"residual_sugar\": [residual_sugar],\n",
    "        \"chlorides\": [chlorides],\n",
    "        \"free_sulfur_dioxide\": [free_sulfur_dioxide],\n",
    "        \"total_sulfur_dioxide\": [total_sulfur_dioxide],\n",
    "        \"density\": [density],\n",
    "        \"pH\": [pH],\n",
    "        \"sulphates\": [sulphates],\n",
    "        \"alcohol\": [alcohol]\n",
    "    })\n",
    "\n",
    "    # scale the X input df \n",
    "    X_scaled = X_scaler.transform(input_df)\n",
    "\n",
    "    # obtain prediction (y) \n",
    "    prediction_scaled = model.predict(X_scaled)\n",
    "    \n",
    "    # scale prediction to human readable terms\n",
    "    prediction = y_scaler.inverse_transform(prediction_scaled)\n",
    "\n",
    "    return prediction \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare user_input to go into the predict function \n",
    "def scaledata(X_scaler, user_inputs):\n",
    "    # get the user input data \n",
    "    fixed_acidity = user_inputs[\"fixed acidity\"]\n",
    "    volatile_acidity = user_inputs[\"volatile acidity\"]\n",
    "    citric_acid = user_inputs[\"citric acid\"]\n",
    "    residual_sugar = user_inputs[\"residual sugar\"]\n",
    "    chlorides = user_inputs[\"chlorides\"]\n",
    "    free_sulfur_dioxide = user_inputs[\"free sulfur dioxide\"]\n",
    "    total_sulfur_dioxide = user_inputs[\"total sulfur dioxide\"]\n",
    "    density = user_inputs[\"density\"]\n",
    "    pH = user_inputs[\"pH\"]\n",
    "    sulphates = user_inputs[\"sulphates\"]\n",
    "    alcohol = user_inputs[\"alcohol\"]\n",
    "\n",
    "    # store input data into df \n",
    "    input_df = pd.DataFrame({\n",
    "        \"fixed_acidity\": [fixed_acidity],\n",
    "        \"volatile_acidity\": [volatile_acidity],\n",
    "        \"citric_acid\": [citric_acid],\n",
    "        \"residual_sugar\": [residual_sugar],\n",
    "        \"chlorides\": [chlorides],\n",
    "        \"free_sulfur_dioxide\": [free_sulfur_dioxide],\n",
    "        \"total_sulfur_dioxide\": [total_sulfur_dioxide],\n",
    "        \"density\": [density],\n",
    "        \"pH\": [pH],\n",
    "        \"sulphates\": [sulphates],\n",
    "        \"alcohol\": [alcohol]\n",
    "    })\n",
    "\n",
    "    # scale the X input df \n",
    "    X_scaled = X_scaler.transform(input_df)\n",
    "\n",
    "    return X_scaled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow          predict quality score is: 7   vs expected result of 7\n",
      "Linear model        predict quality score is: 6.6 vs expected result of 7\n",
      "KNN model           predict quality score is: 6   vs expected result of 7\n",
      "Random Forest model predict quality score is: 7   vs expected result of 7\n"
     ]
    }
   ],
   "source": [
    "# Test a single prediction using different models \n",
    "# Tensor flow model: accuracy: 0.9950\n",
    "# linearmodel : Score = 0.338\n",
    "# RandomForestClassifiermodel : Score = 0.6825\n",
    "# knn : Score = 0.6125\n",
    "\n",
    "index_on_test_dataset = 155\n",
    "user_inputs = X_test.iloc[index_on_test_dataset]\n",
    "expectedresult = y_test[index_on_test_dataset][0]\n",
    "\n",
    "# Using Tensorflow model\n",
    "X_scaled = scaledata(X_scaler, user_inputs)\n",
    "encoded_predictions = model.predict_classes(X_scaled[:5])\n",
    "prediction_labels = label_encoder.inverse_transform(encoded_predictions)\n",
    "print(f\"Tensorflow          predict quality score is: {prediction_labels[0]}   vs expected result of {expectedresult}\")\n",
    "\n",
    "# Using linearmodel\n",
    "print(f\"Linear model        predict quality score is: {predict(linearmodel, X_scaler, y_scaler, user_inputs)[0][0].round(1)} vs expected result of {expectedresult}\")\n",
    "\n",
    "#Using KNN model\n",
    "X_scaled = scaledata(X_scaler, user_inputs)\n",
    "predicted_quality = knn.predict(X_scaled)\n",
    "print(f\"KNN model           predict quality score is: {predicted_quality[0]}   vs expected result of {expectedresult}\")\n",
    "\n",
    "#Using random forest model\n",
    "X_scaled = scaledata(X_scaler, user_inputs)\n",
    "predicted_quality = RandomForestClassifiermodel.predict(X_scaled)\n",
    "print(f\"Random Forest model predict quality score is: {predicted_quality[0]}   vs expected result of {expectedresult}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../app/static/py/encoder.sav']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save model\n",
    "import joblib \n",
    "\n",
    "model.save(\"../app/static/py/model_trained.h5\")\n",
    "joblib.dump(y_scaler, \"../app/static/py/y_scaler.sav\")\n",
    "joblib.dump(X_scaler, \"../app/static/py/x_scaler.sav\")\n",
    "joblib.dump(label_encoder, \"../app/static/py/encoder.sav\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "23a582b2fcb0d9f1a6df63352f294e1d6ca5ce9199f319a44fc346f4901363b4"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('PythonData')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
