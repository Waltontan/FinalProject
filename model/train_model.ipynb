{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependents\n",
    "import pandas as pd \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data CSV \n",
    "df_og = pd.read_csv(\"../resources/winequality-red.csv\")\n",
    "\n",
    "df_og=df_og.rename(columns={'fixed acidity':'fixed_acidity',\n",
    "'volatile acidity':'volatile_acidity',\n",
    "'citric acid':'citric_acid',\n",
    "'residual sugar':'residual_sugar',\n",
    "'free sulfur dioxide':'free_sulfur_dioxide',\n",
    "'total sulfur dioxide':'total_sulfur_dioxide'})\n",
    "df_og.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining X and Y axis for machine learning\n",
    "X = df_og[[\n",
    "    \"fixed_acidity\", \n",
    "    \"volatile_acidity\", \n",
    "    \"citric_acid\", \n",
    "    \"residual_sugar\", \n",
    "    \"chlorides\", \n",
    "    \"free_sulfur_dioxide\", \n",
    "    \"total_sulfur_dioxide\", \n",
    "    \"density\", \n",
    "    \"pH\", \n",
    "    \"sulphates\",\n",
    "    \"alcohol\"\n",
    "]]\n",
    "\n",
    "y = df_og[\"quality\"].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Data for training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling data to improve machine learning accuracy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "y_scaler = StandardScaler().fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "y_train_scaled = y_scaler.transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23114944389009684"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the linearmodel \n",
    "from sklearn.linear_model import LinearRegression\n",
    "linearmodel = LinearRegression()\n",
    "linearmodel.fit(X_train_scaled, y_train_scaled)\n",
    "linearmodel.score(X_test_scaled, y_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7125"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the RandomForestClassifiermodel \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RandomForestClassifiermodel = RandomForestClassifier(n_estimators=200)\n",
    "RandomForestClassifiermodel.fit(X_train_scaled, y_train)\n",
    "RandomForestClassifiermodel.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07194157, 0.10304084, 0.07399159, 0.06982811, 0.08206834,\n",
       "       0.06799565, 0.1015316 , 0.09029043, 0.07263097, 0.11436268,\n",
       "       0.15231821])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display which category is more important\n",
    "importances = RandomForestClassifiermodel.feature_importances_\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting train and test accuracy for KNN model to determine number of neighbours to use\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 40, 1):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    train_score = knn.score(X_train_scaled, y_train)\n",
    "    test_score = knn.score(X_test_scaled, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "\n",
    "plt.plot(range(1, 40, 1), train_scores, marker='o')\n",
    "plt.plot(range(1, 40, 1), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6075"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the KNN model base on the optimised number of neighbour\n",
    "knn = KNeighborsClassifier(n_neighbors=25)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "train_score = knn.score(X_train_scaled, y_train)\n",
    "test_score = knn.score(X_test_scaled, y_test)\n",
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating encoder for neural network model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# One-hot encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_categorical[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining layers in the neural network model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=11))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=6, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 100)               1200      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 11,906\n",
      "Trainable params: 11,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the neural network model\n",
    "model.compile(optimizer='adam', loss=\"categorical_crossentropy\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "38/38 - 0s - loss: 1.2800 - accuracy: 0.4979\n",
      "Epoch 2/500\n",
      "38/38 - 0s - loss: 0.9919 - accuracy: 0.6038\n",
      "Epoch 3/500\n",
      "38/38 - 0s - loss: 0.9377 - accuracy: 0.6147\n",
      "Epoch 4/500\n",
      "38/38 - 0s - loss: 0.9104 - accuracy: 0.6280\n",
      "Epoch 5/500\n",
      "38/38 - 0s - loss: 0.8915 - accuracy: 0.6322\n",
      "Epoch 6/500\n",
      "38/38 - 0s - loss: 0.8698 - accuracy: 0.6380\n",
      "Epoch 7/500\n",
      "38/38 - 0s - loss: 0.8583 - accuracy: 0.6505\n",
      "Epoch 8/500\n",
      "38/38 - 0s - loss: 0.8409 - accuracy: 0.6489\n",
      "Epoch 9/500\n",
      "38/38 - 0s - loss: 0.8332 - accuracy: 0.6514\n",
      "Epoch 10/500\n",
      "38/38 - 0s - loss: 0.8187 - accuracy: 0.6589\n",
      "Epoch 11/500\n",
      "38/38 - 0s - loss: 0.8091 - accuracy: 0.6489\n",
      "Epoch 12/500\n",
      "38/38 - 0s - loss: 0.7989 - accuracy: 0.6622\n",
      "Epoch 13/500\n",
      "38/38 - 0s - loss: 0.7850 - accuracy: 0.6580\n",
      "Epoch 14/500\n",
      "38/38 - 0s - loss: 0.7746 - accuracy: 0.6739\n",
      "Epoch 15/500\n",
      "38/38 - 0s - loss: 0.7682 - accuracy: 0.6580\n",
      "Epoch 16/500\n",
      "38/38 - 0s - loss: 0.7601 - accuracy: 0.6822\n",
      "Epoch 17/500\n",
      "38/38 - 0s - loss: 0.7470 - accuracy: 0.6772\n",
      "Epoch 18/500\n",
      "38/38 - 0s - loss: 0.7425 - accuracy: 0.6939\n",
      "Epoch 19/500\n",
      "38/38 - 0s - loss: 0.7272 - accuracy: 0.7073\n",
      "Epoch 20/500\n",
      "38/38 - 0s - loss: 0.7200 - accuracy: 0.7064\n",
      "Epoch 21/500\n",
      "38/38 - 0s - loss: 0.7044 - accuracy: 0.7114\n",
      "Epoch 22/500\n",
      "38/38 - 0s - loss: 0.7089 - accuracy: 0.7039\n",
      "Epoch 23/500\n",
      "38/38 - 0s - loss: 0.6992 - accuracy: 0.7081\n",
      "Epoch 24/500\n",
      "38/38 - 0s - loss: 0.6785 - accuracy: 0.7214\n",
      "Epoch 25/500\n",
      "38/38 - 0s - loss: 0.6744 - accuracy: 0.7223\n",
      "Epoch 26/500\n",
      "38/38 - 0s - loss: 0.6602 - accuracy: 0.7415\n",
      "Epoch 27/500\n",
      "38/38 - 0s - loss: 0.6518 - accuracy: 0.7389\n",
      "Epoch 28/500\n",
      "38/38 - 0s - loss: 0.6486 - accuracy: 0.7331\n",
      "Epoch 29/500\n",
      "38/38 - 0s - loss: 0.6446 - accuracy: 0.7373\n",
      "Epoch 30/500\n",
      "38/38 - 0s - loss: 0.6288 - accuracy: 0.7548\n",
      "Epoch 31/500\n",
      "38/38 - 0s - loss: 0.6290 - accuracy: 0.7440\n",
      "Epoch 32/500\n",
      "38/38 - 0s - loss: 0.6138 - accuracy: 0.7623\n",
      "Epoch 33/500\n",
      "38/38 - 0s - loss: 0.6047 - accuracy: 0.7723\n",
      "Epoch 34/500\n",
      "38/38 - 0s - loss: 0.5941 - accuracy: 0.7648\n",
      "Epoch 35/500\n",
      "38/38 - 0s - loss: 0.5860 - accuracy: 0.7706\n",
      "Epoch 36/500\n",
      "38/38 - 0s - loss: 0.5909 - accuracy: 0.7648\n",
      "Epoch 37/500\n",
      "38/38 - 0s - loss: 0.5739 - accuracy: 0.7590\n",
      "Epoch 38/500\n",
      "38/38 - 0s - loss: 0.5733 - accuracy: 0.7731\n",
      "Epoch 39/500\n",
      "38/38 - 0s - loss: 0.5777 - accuracy: 0.7740\n",
      "Epoch 40/500\n",
      "38/38 - 0s - loss: 0.5550 - accuracy: 0.7882\n",
      "Epoch 41/500\n",
      "38/38 - 0s - loss: 0.5426 - accuracy: 0.7990\n",
      "Epoch 42/500\n",
      "38/38 - 0s - loss: 0.5502 - accuracy: 0.7823\n",
      "Epoch 43/500\n",
      "38/38 - 0s - loss: 0.5370 - accuracy: 0.7857\n",
      "Epoch 44/500\n",
      "38/38 - 0s - loss: 0.5234 - accuracy: 0.8007\n",
      "Epoch 45/500\n",
      "38/38 - 0s - loss: 0.5127 - accuracy: 0.8115\n",
      "Epoch 46/500\n",
      "38/38 - 0s - loss: 0.5244 - accuracy: 0.7890\n",
      "Epoch 47/500\n",
      "38/38 - 0s - loss: 0.5043 - accuracy: 0.8007\n",
      "Epoch 48/500\n",
      "38/38 - 0s - loss: 0.5007 - accuracy: 0.8123\n",
      "Epoch 49/500\n",
      "38/38 - 0s - loss: 0.4939 - accuracy: 0.8048\n",
      "Epoch 50/500\n",
      "38/38 - 0s - loss: 0.4878 - accuracy: 0.8140\n",
      "Epoch 51/500\n",
      "38/38 - 0s - loss: 0.4767 - accuracy: 0.8165\n",
      "Epoch 52/500\n",
      "38/38 - 0s - loss: 0.4724 - accuracy: 0.8232\n",
      "Epoch 53/500\n",
      "38/38 - 0s - loss: 0.4662 - accuracy: 0.8157\n",
      "Epoch 54/500\n",
      "38/38 - 0s - loss: 0.4589 - accuracy: 0.8332\n",
      "Epoch 55/500\n",
      "38/38 - 0s - loss: 0.4561 - accuracy: 0.8207\n",
      "Epoch 56/500\n",
      "38/38 - 0s - loss: 0.4446 - accuracy: 0.8399\n",
      "Epoch 57/500\n",
      "38/38 - 0s - loss: 0.4427 - accuracy: 0.8340\n",
      "Epoch 58/500\n",
      "38/38 - 0s - loss: 0.4396 - accuracy: 0.8399\n",
      "Epoch 59/500\n",
      "38/38 - 0s - loss: 0.4357 - accuracy: 0.8324\n",
      "Epoch 60/500\n",
      "38/38 - 0s - loss: 0.4350 - accuracy: 0.8265\n",
      "Epoch 61/500\n",
      "38/38 - 0s - loss: 0.4227 - accuracy: 0.8449\n",
      "Epoch 62/500\n",
      "38/38 - 0s - loss: 0.4118 - accuracy: 0.8490\n",
      "Epoch 63/500\n",
      "38/38 - 0s - loss: 0.4096 - accuracy: 0.8540\n",
      "Epoch 64/500\n",
      "38/38 - 0s - loss: 0.4021 - accuracy: 0.8465\n",
      "Epoch 65/500\n",
      "38/38 - 0s - loss: 0.4007 - accuracy: 0.8524\n",
      "Epoch 66/500\n",
      "38/38 - 0s - loss: 0.3864 - accuracy: 0.8549\n",
      "Epoch 67/500\n",
      "38/38 - 0s - loss: 0.3864 - accuracy: 0.8590\n",
      "Epoch 68/500\n",
      "38/38 - 0s - loss: 0.3775 - accuracy: 0.8607\n",
      "Epoch 69/500\n",
      "38/38 - 0s - loss: 0.3768 - accuracy: 0.8616\n",
      "Epoch 70/500\n",
      "38/38 - 0s - loss: 0.3754 - accuracy: 0.8616\n",
      "Epoch 71/500\n",
      "38/38 - 0s - loss: 0.3655 - accuracy: 0.8682\n",
      "Epoch 72/500\n",
      "38/38 - 0s - loss: 0.3650 - accuracy: 0.8699\n",
      "Epoch 73/500\n",
      "38/38 - 0s - loss: 0.3528 - accuracy: 0.8807\n",
      "Epoch 74/500\n",
      "38/38 - 0s - loss: 0.3554 - accuracy: 0.8766\n",
      "Epoch 75/500\n",
      "38/38 - 0s - loss: 0.3623 - accuracy: 0.8691\n",
      "Epoch 76/500\n",
      "38/38 - 0s - loss: 0.3522 - accuracy: 0.8816\n",
      "Epoch 77/500\n",
      "38/38 - 0s - loss: 0.3456 - accuracy: 0.8874\n",
      "Epoch 78/500\n",
      "38/38 - 0s - loss: 0.3266 - accuracy: 0.8841\n",
      "Epoch 79/500\n",
      "38/38 - 0s - loss: 0.3204 - accuracy: 0.9016\n",
      "Epoch 80/500\n",
      "38/38 - 0s - loss: 0.3225 - accuracy: 0.8999\n",
      "Epoch 81/500\n",
      "38/38 - 0s - loss: 0.3118 - accuracy: 0.8941\n",
      "Epoch 82/500\n",
      "38/38 - 0s - loss: 0.3113 - accuracy: 0.8991\n",
      "Epoch 83/500\n",
      "38/38 - 0s - loss: 0.3074 - accuracy: 0.9024\n",
      "Epoch 84/500\n",
      "38/38 - 0s - loss: 0.3003 - accuracy: 0.8966\n",
      "Epoch 85/500\n",
      "38/38 - 0s - loss: 0.3047 - accuracy: 0.8957\n",
      "Epoch 86/500\n",
      "38/38 - 0s - loss: 0.2943 - accuracy: 0.9041\n",
      "Epoch 87/500\n",
      "38/38 - 0s - loss: 0.2856 - accuracy: 0.9124\n",
      "Epoch 88/500\n",
      "38/38 - 0s - loss: 0.2931 - accuracy: 0.9058\n",
      "Epoch 89/500\n",
      "38/38 - 0s - loss: 0.2777 - accuracy: 0.9158\n",
      "Epoch 90/500\n",
      "38/38 - 0s - loss: 0.2759 - accuracy: 0.9091\n",
      "Epoch 91/500\n",
      "38/38 - 0s - loss: 0.2610 - accuracy: 0.9224\n",
      "Epoch 92/500\n",
      "38/38 - 0s - loss: 0.2712 - accuracy: 0.9133\n",
      "Epoch 93/500\n",
      "38/38 - 0s - loss: 0.2628 - accuracy: 0.9183\n",
      "Epoch 94/500\n",
      "38/38 - 0s - loss: 0.2745 - accuracy: 0.9083\n",
      "Epoch 95/500\n",
      "38/38 - 0s - loss: 0.2560 - accuracy: 0.9191\n",
      "Epoch 96/500\n",
      "38/38 - 0s - loss: 0.2556 - accuracy: 0.9233\n",
      "Epoch 97/500\n",
      "38/38 - 0s - loss: 0.2535 - accuracy: 0.9224\n",
      "Epoch 98/500\n",
      "38/38 - 0s - loss: 0.2502 - accuracy: 0.9174\n",
      "Epoch 99/500\n",
      "38/38 - 0s - loss: 0.2488 - accuracy: 0.9183\n",
      "Epoch 100/500\n",
      "38/38 - 0s - loss: 0.2396 - accuracy: 0.9266\n",
      "Epoch 101/500\n",
      "38/38 - 0s - loss: 0.2329 - accuracy: 0.9366\n",
      "Epoch 102/500\n",
      "38/38 - 0s - loss: 0.2288 - accuracy: 0.9308\n",
      "Epoch 103/500\n",
      "38/38 - 0s - loss: 0.2277 - accuracy: 0.9341\n",
      "Epoch 104/500\n",
      "38/38 - 0s - loss: 0.2246 - accuracy: 0.9299\n",
      "Epoch 105/500\n",
      "38/38 - 0s - loss: 0.2201 - accuracy: 0.9391\n",
      "Epoch 106/500\n",
      "38/38 - 0s - loss: 0.2213 - accuracy: 0.9366\n",
      "Epoch 107/500\n",
      "38/38 - 0s - loss: 0.2154 - accuracy: 0.9383\n",
      "Epoch 108/500\n",
      "38/38 - 0s - loss: 0.2053 - accuracy: 0.9500\n",
      "Epoch 109/500\n",
      "38/38 - 0s - loss: 0.2000 - accuracy: 0.9475\n",
      "Epoch 110/500\n",
      "38/38 - 0s - loss: 0.2066 - accuracy: 0.9466\n",
      "Epoch 111/500\n",
      "38/38 - 0s - loss: 0.1984 - accuracy: 0.9450\n",
      "Epoch 112/500\n",
      "38/38 - 0s - loss: 0.2127 - accuracy: 0.9349\n",
      "Epoch 113/500\n",
      "38/38 - 0s - loss: 0.1977 - accuracy: 0.9516\n",
      "Epoch 114/500\n",
      "38/38 - 0s - loss: 0.1852 - accuracy: 0.9516\n",
      "Epoch 115/500\n",
      "38/38 - 0s - loss: 0.1911 - accuracy: 0.9475\n",
      "Epoch 116/500\n",
      "38/38 - 0s - loss: 0.1819 - accuracy: 0.9566\n",
      "Epoch 117/500\n",
      "38/38 - 0s - loss: 0.1815 - accuracy: 0.9591\n",
      "Epoch 118/500\n",
      "38/38 - 0s - loss: 0.1868 - accuracy: 0.9491\n",
      "Epoch 119/500\n",
      "38/38 - 0s - loss: 0.1901 - accuracy: 0.9425\n",
      "Epoch 120/500\n",
      "38/38 - 0s - loss: 0.1734 - accuracy: 0.9575\n",
      "Epoch 121/500\n",
      "38/38 - 0s - loss: 0.1737 - accuracy: 0.9583\n",
      "Epoch 122/500\n",
      "38/38 - 0s - loss: 0.1722 - accuracy: 0.9575\n",
      "Epoch 123/500\n",
      "38/38 - 0s - loss: 0.1652 - accuracy: 0.9658\n",
      "Epoch 124/500\n",
      "38/38 - 0s - loss: 0.1585 - accuracy: 0.9600\n",
      "Epoch 125/500\n",
      "38/38 - 0s - loss: 0.1576 - accuracy: 0.9641\n",
      "Epoch 126/500\n",
      "38/38 - 0s - loss: 0.1495 - accuracy: 0.9716\n",
      "Epoch 127/500\n",
      "38/38 - 0s - loss: 0.1508 - accuracy: 0.9683\n",
      "Epoch 128/500\n",
      "38/38 - 0s - loss: 0.1657 - accuracy: 0.9683\n",
      "Epoch 129/500\n",
      "38/38 - 0s - loss: 0.1608 - accuracy: 0.9591\n",
      "Epoch 130/500\n",
      "38/38 - 0s - loss: 0.1619 - accuracy: 0.9608\n",
      "Epoch 131/500\n",
      "38/38 - 0s - loss: 0.1549 - accuracy: 0.9583\n",
      "Epoch 132/500\n",
      "38/38 - 0s - loss: 0.1646 - accuracy: 0.9600\n",
      "Epoch 133/500\n",
      "38/38 - 0s - loss: 0.1487 - accuracy: 0.9583\n",
      "Epoch 134/500\n",
      "38/38 - 0s - loss: 0.1419 - accuracy: 0.9716\n",
      "Epoch 135/500\n",
      "38/38 - 0s - loss: 0.1376 - accuracy: 0.9708\n",
      "Epoch 136/500\n",
      "38/38 - 0s - loss: 0.1329 - accuracy: 0.9733\n",
      "Epoch 137/500\n",
      "38/38 - 0s - loss: 0.1299 - accuracy: 0.9750\n",
      "Epoch 138/500\n",
      "38/38 - 0s - loss: 0.1243 - accuracy: 0.9791\n",
      "Epoch 139/500\n",
      "38/38 - 0s - loss: 0.1268 - accuracy: 0.9783\n",
      "Epoch 140/500\n",
      "38/38 - 0s - loss: 0.1271 - accuracy: 0.9808\n",
      "Epoch 141/500\n",
      "38/38 - 0s - loss: 0.1185 - accuracy: 0.9783\n",
      "Epoch 142/500\n",
      "38/38 - 0s - loss: 0.1156 - accuracy: 0.9825\n",
      "Epoch 143/500\n",
      "38/38 - 0s - loss: 0.1166 - accuracy: 0.9758\n",
      "Epoch 144/500\n",
      "38/38 - 0s - loss: 0.1225 - accuracy: 0.9766\n",
      "Epoch 145/500\n",
      "38/38 - 0s - loss: 0.1187 - accuracy: 0.9741\n",
      "Epoch 146/500\n",
      "38/38 - 0s - loss: 0.1159 - accuracy: 0.9750\n",
      "Epoch 147/500\n",
      "38/38 - 0s - loss: 0.1108 - accuracy: 0.9817\n",
      "Epoch 148/500\n",
      "38/38 - 0s - loss: 0.1106 - accuracy: 0.9817\n",
      "Epoch 149/500\n",
      "38/38 - 0s - loss: 0.1116 - accuracy: 0.9817\n",
      "Epoch 150/500\n",
      "38/38 - 0s - loss: 0.1000 - accuracy: 0.9817\n",
      "Epoch 151/500\n",
      "38/38 - 0s - loss: 0.1013 - accuracy: 0.9858\n",
      "Epoch 152/500\n",
      "38/38 - 0s - loss: 0.1042 - accuracy: 0.9825\n",
      "Epoch 153/500\n",
      "38/38 - 0s - loss: 0.0979 - accuracy: 0.9875\n",
      "Epoch 154/500\n",
      "38/38 - 0s - loss: 0.0984 - accuracy: 0.9850\n",
      "Epoch 155/500\n",
      "38/38 - 0s - loss: 0.0953 - accuracy: 0.9825\n",
      "Epoch 156/500\n",
      "38/38 - 0s - loss: 0.1117 - accuracy: 0.9783\n",
      "Epoch 157/500\n",
      "38/38 - 0s - loss: 0.1144 - accuracy: 0.9716\n",
      "Epoch 158/500\n",
      "38/38 - 0s - loss: 0.1072 - accuracy: 0.9775\n",
      "Epoch 159/500\n",
      "38/38 - 0s - loss: 0.1109 - accuracy: 0.9741\n",
      "Epoch 160/500\n",
      "38/38 - 0s - loss: 0.1069 - accuracy: 0.9867\n",
      "Epoch 161/500\n",
      "38/38 - 0s - loss: 0.0986 - accuracy: 0.9842\n",
      "Epoch 162/500\n",
      "38/38 - 0s - loss: 0.0875 - accuracy: 0.9883\n",
      "Epoch 163/500\n",
      "38/38 - 0s - loss: 0.0855 - accuracy: 0.9900\n",
      "Epoch 164/500\n",
      "38/38 - 0s - loss: 0.0806 - accuracy: 0.9917\n",
      "Epoch 165/500\n",
      "38/38 - 0s - loss: 0.0847 - accuracy: 0.9883\n",
      "Epoch 166/500\n",
      "38/38 - 0s - loss: 0.0885 - accuracy: 0.9842\n",
      "Epoch 167/500\n",
      "38/38 - 0s - loss: 0.0891 - accuracy: 0.9867\n",
      "Epoch 168/500\n",
      "38/38 - 0s - loss: 0.0830 - accuracy: 0.9892\n",
      "Epoch 169/500\n",
      "38/38 - 0s - loss: 0.0895 - accuracy: 0.9833\n",
      "Epoch 170/500\n",
      "38/38 - 0s - loss: 0.0830 - accuracy: 0.9908\n",
      "Epoch 171/500\n",
      "38/38 - 0s - loss: 0.0849 - accuracy: 0.9883\n",
      "Epoch 172/500\n",
      "38/38 - 0s - loss: 0.0764 - accuracy: 0.9925\n",
      "Epoch 173/500\n",
      "38/38 - 0s - loss: 0.0784 - accuracy: 0.9875\n",
      "Epoch 174/500\n",
      "38/38 - 0s - loss: 0.0709 - accuracy: 0.9925\n",
      "Epoch 175/500\n",
      "38/38 - 0s - loss: 0.0738 - accuracy: 0.9892\n",
      "Epoch 176/500\n",
      "38/38 - 0s - loss: 0.0709 - accuracy: 0.9892\n",
      "Epoch 177/500\n",
      "38/38 - 0s - loss: 0.0692 - accuracy: 0.9908\n",
      "Epoch 178/500\n",
      "38/38 - 0s - loss: 0.0653 - accuracy: 0.9942\n",
      "Epoch 179/500\n",
      "38/38 - 0s - loss: 0.0737 - accuracy: 0.9867\n",
      "Epoch 180/500\n",
      "38/38 - 0s - loss: 0.0762 - accuracy: 0.9908\n",
      "Epoch 181/500\n",
      "38/38 - 0s - loss: 0.0696 - accuracy: 0.9917\n",
      "Epoch 182/500\n",
      "38/38 - 0s - loss: 0.0993 - accuracy: 0.9808\n",
      "Epoch 183/500\n",
      "38/38 - 0s - loss: 0.0740 - accuracy: 0.9908\n",
      "Epoch 184/500\n",
      "38/38 - 0s - loss: 0.0814 - accuracy: 0.9900\n",
      "Epoch 185/500\n",
      "38/38 - 0s - loss: 0.0657 - accuracy: 0.9908\n",
      "Epoch 186/500\n",
      "38/38 - 0s - loss: 0.0677 - accuracy: 0.9917\n",
      "Epoch 187/500\n",
      "38/38 - 0s - loss: 0.0746 - accuracy: 0.9875\n",
      "Epoch 188/500\n",
      "38/38 - 0s - loss: 0.0742 - accuracy: 0.9858\n",
      "Epoch 189/500\n",
      "38/38 - 0s - loss: 0.0615 - accuracy: 0.9925\n",
      "Epoch 190/500\n",
      "38/38 - 0s - loss: 0.0590 - accuracy: 0.9950\n",
      "Epoch 191/500\n",
      "38/38 - 0s - loss: 0.0560 - accuracy: 0.9958\n",
      "Epoch 192/500\n",
      "38/38 - 0s - loss: 0.0584 - accuracy: 0.9900\n",
      "Epoch 193/500\n",
      "38/38 - 0s - loss: 0.0715 - accuracy: 0.9858\n",
      "Epoch 194/500\n",
      "38/38 - 0s - loss: 0.0584 - accuracy: 0.9950\n",
      "Epoch 195/500\n",
      "38/38 - 0s - loss: 0.0556 - accuracy: 0.9950\n",
      "Epoch 196/500\n",
      "38/38 - 0s - loss: 0.0526 - accuracy: 0.9950\n",
      "Epoch 197/500\n",
      "38/38 - 0s - loss: 0.0510 - accuracy: 0.9958\n",
      "Epoch 198/500\n",
      "38/38 - 0s - loss: 0.0571 - accuracy: 0.9933\n",
      "Epoch 199/500\n",
      "38/38 - 0s - loss: 0.0486 - accuracy: 0.9950\n",
      "Epoch 200/500\n",
      "38/38 - 0s - loss: 0.0496 - accuracy: 0.9950\n",
      "Epoch 201/500\n",
      "38/38 - 0s - loss: 0.0491 - accuracy: 0.9950\n",
      "Epoch 202/500\n",
      "38/38 - 0s - loss: 0.0799 - accuracy: 0.9850\n",
      "Epoch 203/500\n",
      "38/38 - 0s - loss: 0.0697 - accuracy: 0.9833\n",
      "Epoch 204/500\n",
      "38/38 - 0s - loss: 0.0547 - accuracy: 0.9900\n",
      "Epoch 205/500\n",
      "38/38 - 0s - loss: 0.0652 - accuracy: 0.9917\n",
      "Epoch 206/500\n",
      "38/38 - 0s - loss: 0.0544 - accuracy: 0.9933\n",
      "Epoch 207/500\n",
      "38/38 - 0s - loss: 0.0499 - accuracy: 0.9933\n",
      "Epoch 208/500\n",
      "38/38 - 0s - loss: 0.0500 - accuracy: 0.9925\n",
      "Epoch 209/500\n",
      "38/38 - 0s - loss: 0.0499 - accuracy: 0.9950\n",
      "Epoch 210/500\n",
      "38/38 - 0s - loss: 0.0584 - accuracy: 0.9900\n",
      "Epoch 211/500\n",
      "38/38 - 0s - loss: 0.0631 - accuracy: 0.9842\n",
      "Epoch 212/500\n",
      "38/38 - 0s - loss: 0.0518 - accuracy: 0.9925\n",
      "Epoch 213/500\n",
      "38/38 - 0s - loss: 0.0468 - accuracy: 0.9942\n",
      "Epoch 214/500\n",
      "38/38 - 0s - loss: 0.0474 - accuracy: 0.9950\n",
      "Epoch 215/500\n",
      "38/38 - 0s - loss: 0.0761 - accuracy: 0.9833\n",
      "Epoch 216/500\n",
      "38/38 - 0s - loss: 0.0729 - accuracy: 0.9825\n",
      "Epoch 217/500\n",
      "38/38 - 0s - loss: 0.0530 - accuracy: 0.9917\n",
      "Epoch 218/500\n",
      "38/38 - 0s - loss: 0.0377 - accuracy: 0.9933\n",
      "Epoch 219/500\n",
      "38/38 - 0s - loss: 0.0471 - accuracy: 0.9933\n",
      "Epoch 220/500\n",
      "38/38 - 0s - loss: 0.0396 - accuracy: 0.9942\n",
      "Epoch 221/500\n",
      "38/38 - 0s - loss: 0.0371 - accuracy: 0.9967\n",
      "Epoch 222/500\n",
      "38/38 - 0s - loss: 0.0394 - accuracy: 0.9975\n",
      "Epoch 223/500\n",
      "38/38 - 0s - loss: 0.0381 - accuracy: 0.9950\n",
      "Epoch 224/500\n",
      "38/38 - 0s - loss: 0.0390 - accuracy: 0.9967\n",
      "Epoch 225/500\n",
      "38/38 - 0s - loss: 0.0403 - accuracy: 0.9958\n",
      "Epoch 226/500\n",
      "38/38 - 0s - loss: 0.0419 - accuracy: 0.9975\n",
      "Epoch 227/500\n",
      "38/38 - 0s - loss: 0.0347 - accuracy: 0.9967\n",
      "Epoch 228/500\n",
      "38/38 - 0s - loss: 0.0419 - accuracy: 0.9958\n",
      "Epoch 229/500\n",
      "38/38 - 0s - loss: 0.0429 - accuracy: 0.9942\n",
      "Epoch 230/500\n",
      "38/38 - 0s - loss: 0.0461 - accuracy: 0.9917\n",
      "Epoch 231/500\n",
      "38/38 - 0s - loss: 0.0433 - accuracy: 0.9942\n",
      "Epoch 232/500\n",
      "38/38 - 0s - loss: 0.0341 - accuracy: 0.9950\n",
      "Epoch 233/500\n",
      "38/38 - 0s - loss: 0.0364 - accuracy: 0.9950\n",
      "Epoch 234/500\n",
      "38/38 - 0s - loss: 0.0335 - accuracy: 0.9942\n",
      "Epoch 235/500\n",
      "38/38 - 0s - loss: 0.0309 - accuracy: 0.9975\n",
      "Epoch 236/500\n",
      "38/38 - 0s - loss: 0.0431 - accuracy: 0.9942\n",
      "Epoch 237/500\n",
      "38/38 - 0s - loss: 0.0379 - accuracy: 0.9950\n",
      "Epoch 238/500\n",
      "38/38 - 0s - loss: 0.0316 - accuracy: 0.9942\n",
      "Epoch 239/500\n",
      "38/38 - 0s - loss: 0.0430 - accuracy: 0.9925\n",
      "Epoch 240/500\n",
      "38/38 - 0s - loss: 0.0369 - accuracy: 0.9958\n",
      "Epoch 241/500\n",
      "38/38 - 0s - loss: 0.0383 - accuracy: 0.9958\n",
      "Epoch 242/500\n",
      "38/38 - 0s - loss: 0.0374 - accuracy: 0.9942\n",
      "Epoch 243/500\n",
      "38/38 - 0s - loss: 0.0469 - accuracy: 0.9917\n",
      "Epoch 244/500\n",
      "38/38 - 0s - loss: 0.0342 - accuracy: 0.9958\n",
      "Epoch 245/500\n",
      "38/38 - 0s - loss: 0.0328 - accuracy: 0.9967\n",
      "Epoch 246/500\n",
      "38/38 - 0s - loss: 0.0279 - accuracy: 0.9967\n",
      "Epoch 247/500\n",
      "38/38 - 0s - loss: 0.0304 - accuracy: 0.9975\n",
      "Epoch 248/500\n",
      "38/38 - 0s - loss: 0.0340 - accuracy: 0.9958\n",
      "Epoch 249/500\n",
      "38/38 - 0s - loss: 0.0282 - accuracy: 0.9967\n",
      "Epoch 250/500\n",
      "38/38 - 0s - loss: 0.0322 - accuracy: 0.9958\n",
      "Epoch 251/500\n",
      "38/38 - 0s - loss: 0.0411 - accuracy: 0.9933\n",
      "Epoch 252/500\n",
      "38/38 - 0s - loss: 0.0329 - accuracy: 0.9942\n",
      "Epoch 253/500\n",
      "38/38 - 0s - loss: 0.0377 - accuracy: 0.9950\n",
      "Epoch 254/500\n",
      "38/38 - 0s - loss: 0.0386 - accuracy: 0.9942\n",
      "Epoch 255/500\n",
      "38/38 - 0s - loss: 0.0377 - accuracy: 0.9933\n",
      "Epoch 256/500\n",
      "38/38 - 0s - loss: 0.0391 - accuracy: 0.9933\n",
      "Epoch 257/500\n",
      "38/38 - 0s - loss: 0.0309 - accuracy: 0.9967\n",
      "Epoch 258/500\n",
      "38/38 - 0s - loss: 0.0366 - accuracy: 0.9950\n",
      "Epoch 259/500\n",
      "38/38 - 0s - loss: 0.0369 - accuracy: 0.9925\n",
      "Epoch 260/500\n",
      "38/38 - 0s - loss: 0.0295 - accuracy: 0.9967\n",
      "Epoch 261/500\n",
      "38/38 - 0s - loss: 0.0296 - accuracy: 0.9958\n",
      "Epoch 262/500\n",
      "38/38 - 0s - loss: 0.0250 - accuracy: 0.9975\n",
      "Epoch 263/500\n",
      "38/38 - 0s - loss: 0.0300 - accuracy: 0.9958\n",
      "Epoch 264/500\n",
      "38/38 - 0s - loss: 0.0346 - accuracy: 0.9967\n",
      "Epoch 265/500\n",
      "38/38 - 0s - loss: 0.0273 - accuracy: 0.9967\n",
      "Epoch 266/500\n",
      "38/38 - 0s - loss: 0.0251 - accuracy: 0.9992\n",
      "Epoch 267/500\n",
      "38/38 - 0s - loss: 0.0301 - accuracy: 0.9958\n",
      "Epoch 268/500\n",
      "38/38 - 0s - loss: 0.0259 - accuracy: 0.9967\n",
      "Epoch 269/500\n",
      "38/38 - 0s - loss: 0.0220 - accuracy: 0.9983\n",
      "Epoch 270/500\n",
      "38/38 - 0s - loss: 0.0303 - accuracy: 0.9967\n",
      "Epoch 271/500\n",
      "38/38 - 0s - loss: 0.0280 - accuracy: 0.9967\n",
      "Epoch 272/500\n",
      "38/38 - 0s - loss: 0.0302 - accuracy: 0.9958\n",
      "Epoch 273/500\n",
      "38/38 - 0s - loss: 0.0302 - accuracy: 0.9967\n",
      "Epoch 274/500\n",
      "38/38 - 0s - loss: 0.0262 - accuracy: 0.9967\n",
      "Epoch 275/500\n",
      "38/38 - 0s - loss: 0.0501 - accuracy: 0.9917\n",
      "Epoch 276/500\n",
      "38/38 - 0s - loss: 0.1270 - accuracy: 0.9650\n",
      "Epoch 277/500\n",
      "38/38 - 0s - loss: 0.1099 - accuracy: 0.9566\n",
      "Epoch 278/500\n",
      "38/38 - 0s - loss: 0.0540 - accuracy: 0.9858\n",
      "Epoch 279/500\n",
      "38/38 - 0s - loss: 0.0288 - accuracy: 0.9950\n",
      "Epoch 280/500\n",
      "38/38 - 0s - loss: 0.0437 - accuracy: 0.9925\n",
      "Epoch 281/500\n",
      "38/38 - 0s - loss: 0.0259 - accuracy: 0.9983\n",
      "Epoch 282/500\n",
      "38/38 - 0s - loss: 0.0203 - accuracy: 0.9983\n",
      "Epoch 283/500\n",
      "38/38 - 0s - loss: 0.0289 - accuracy: 0.9958\n",
      "Epoch 284/500\n",
      "38/38 - 0s - loss: 0.0197 - accuracy: 0.9983\n",
      "Epoch 285/500\n",
      "38/38 - 0s - loss: 0.0188 - accuracy: 0.9983\n",
      "Epoch 286/500\n",
      "38/38 - 0s - loss: 0.0202 - accuracy: 0.9983\n",
      "Epoch 287/500\n",
      "38/38 - 0s - loss: 0.0203 - accuracy: 0.9975\n",
      "Epoch 288/500\n",
      "38/38 - 0s - loss: 0.0207 - accuracy: 0.9983\n",
      "Epoch 289/500\n",
      "38/38 - 0s - loss: 0.0201 - accuracy: 0.9975\n",
      "Epoch 290/500\n",
      "38/38 - 0s - loss: 0.0131 - accuracy: 0.9975\n",
      "Epoch 291/500\n",
      "38/38 - 0s - loss: 0.0162 - accuracy: 0.9983\n",
      "Epoch 292/500\n",
      "38/38 - 0s - loss: 0.0292 - accuracy: 0.9958\n",
      "Epoch 293/500\n",
      "38/38 - 0s - loss: 0.0295 - accuracy: 0.9967\n",
      "Epoch 294/500\n",
      "38/38 - 0s - loss: 0.0231 - accuracy: 0.9967\n",
      "Epoch 295/500\n",
      "38/38 - 0s - loss: 0.0226 - accuracy: 0.9975\n",
      "Epoch 296/500\n",
      "38/38 - 0s - loss: 0.0223 - accuracy: 0.9950\n",
      "Epoch 297/500\n",
      "38/38 - 0s - loss: 0.0197 - accuracy: 0.9958\n",
      "Epoch 298/500\n",
      "38/38 - 0s - loss: 0.0163 - accuracy: 0.9967\n",
      "Epoch 299/500\n",
      "38/38 - 0s - loss: 0.0226 - accuracy: 0.9967\n",
      "Epoch 300/500\n",
      "38/38 - 0s - loss: 0.0246 - accuracy: 0.9950\n",
      "Epoch 301/500\n",
      "38/38 - 0s - loss: 0.0245 - accuracy: 0.9975\n",
      "Epoch 302/500\n",
      "38/38 - 0s - loss: 0.0220 - accuracy: 0.9975\n",
      "Epoch 303/500\n",
      "38/38 - 0s - loss: 0.0240 - accuracy: 0.9950\n",
      "Epoch 304/500\n",
      "38/38 - 0s - loss: 0.0198 - accuracy: 0.9967\n",
      "Epoch 305/500\n",
      "38/38 - 0s - loss: 0.0336 - accuracy: 0.9975\n",
      "Epoch 306/500\n",
      "38/38 - 0s - loss: 0.0133 - accuracy: 1.0000\n",
      "Epoch 307/500\n",
      "38/38 - 0s - loss: 0.0161 - accuracy: 0.9975\n",
      "Epoch 308/500\n",
      "38/38 - 0s - loss: 0.0230 - accuracy: 0.9967\n",
      "Epoch 309/500\n",
      "38/38 - 0s - loss: 0.0232 - accuracy: 0.9967\n",
      "Epoch 310/500\n",
      "38/38 - 0s - loss: 0.0154 - accuracy: 0.9975\n",
      "Epoch 311/500\n",
      "38/38 - 0s - loss: 0.0160 - accuracy: 0.9992\n",
      "Epoch 312/500\n",
      "38/38 - 0s - loss: 0.0217 - accuracy: 0.9975\n",
      "Epoch 313/500\n",
      "38/38 - 0s - loss: 0.0143 - accuracy: 0.9975\n",
      "Epoch 314/500\n",
      "38/38 - 0s - loss: 0.0179 - accuracy: 0.9975\n",
      "Epoch 315/500\n",
      "38/38 - 0s - loss: 0.0226 - accuracy: 0.9975\n",
      "Epoch 316/500\n",
      "38/38 - 0s - loss: 0.0217 - accuracy: 0.9958\n",
      "Epoch 317/500\n",
      "38/38 - 0s - loss: 0.0252 - accuracy: 0.9967\n",
      "Epoch 318/500\n",
      "38/38 - 0s - loss: 0.0187 - accuracy: 0.9983\n",
      "Epoch 319/500\n",
      "38/38 - 0s - loss: 0.0219 - accuracy: 0.9950\n",
      "Epoch 320/500\n",
      "38/38 - 0s - loss: 0.0218 - accuracy: 0.9958\n",
      "Epoch 321/500\n",
      "38/38 - 0s - loss: 0.0163 - accuracy: 0.9958\n",
      "Epoch 322/500\n",
      "38/38 - 0s - loss: 0.0186 - accuracy: 0.9967\n",
      "Epoch 323/500\n",
      "38/38 - 0s - loss: 0.0304 - accuracy: 0.9933\n",
      "Epoch 324/500\n",
      "38/38 - 0s - loss: 0.0421 - accuracy: 0.9950\n",
      "Epoch 325/500\n",
      "38/38 - 0s - loss: 0.0191 - accuracy: 0.9975\n",
      "Epoch 326/500\n",
      "38/38 - 0s - loss: 0.0143 - accuracy: 0.9992\n",
      "Epoch 327/500\n",
      "38/38 - 0s - loss: 0.0208 - accuracy: 0.9975\n",
      "Epoch 328/500\n",
      "38/38 - 0s - loss: 0.0401 - accuracy: 0.9942\n",
      "Epoch 329/500\n",
      "38/38 - 0s - loss: 0.0346 - accuracy: 0.9942\n",
      "Epoch 330/500\n",
      "38/38 - 0s - loss: 0.0311 - accuracy: 0.9942\n",
      "Epoch 331/500\n",
      "38/38 - 0s - loss: 0.0596 - accuracy: 0.9917\n",
      "Epoch 332/500\n",
      "38/38 - 0s - loss: 0.0516 - accuracy: 0.9900\n",
      "Epoch 333/500\n",
      "38/38 - 0s - loss: 0.0633 - accuracy: 0.9933\n",
      "Epoch 334/500\n",
      "38/38 - 0s - loss: 0.0757 - accuracy: 0.9791\n",
      "Epoch 335/500\n",
      "38/38 - 0s - loss: 0.0316 - accuracy: 0.9925\n",
      "Epoch 336/500\n",
      "38/38 - 0s - loss: 0.0442 - accuracy: 0.9875\n",
      "Epoch 337/500\n",
      "38/38 - 0s - loss: 0.0278 - accuracy: 0.9958\n",
      "Epoch 338/500\n",
      "38/38 - 0s - loss: 0.0416 - accuracy: 0.9908\n",
      "Epoch 339/500\n",
      "38/38 - 0s - loss: 0.0161 - accuracy: 0.9983\n",
      "Epoch 340/500\n",
      "38/38 - 0s - loss: 0.0151 - accuracy: 0.9992\n",
      "Epoch 341/500\n",
      "38/38 - 0s - loss: 0.0122 - accuracy: 0.9992\n",
      "Epoch 342/500\n",
      "38/38 - 0s - loss: 0.0139 - accuracy: 0.9983\n",
      "Epoch 343/500\n",
      "38/38 - 0s - loss: 0.0170 - accuracy: 0.9975\n",
      "Epoch 344/500\n",
      "38/38 - 0s - loss: 0.0175 - accuracy: 0.9967\n",
      "Epoch 345/500\n",
      "38/38 - 0s - loss: 0.0124 - accuracy: 0.9975\n",
      "Epoch 346/500\n",
      "38/38 - 0s - loss: 0.0163 - accuracy: 0.9983\n",
      "Epoch 347/500\n",
      "38/38 - 0s - loss: 0.0132 - accuracy: 0.9975\n",
      "Epoch 348/500\n",
      "38/38 - 0s - loss: 0.0141 - accuracy: 0.9983\n",
      "Epoch 349/500\n",
      "38/38 - 0s - loss: 0.0148 - accuracy: 0.9975\n",
      "Epoch 350/500\n",
      "38/38 - 0s - loss: 0.0128 - accuracy: 0.9983\n",
      "Epoch 351/500\n",
      "38/38 - 0s - loss: 0.0120 - accuracy: 0.9983\n",
      "Epoch 352/500\n",
      "38/38 - 0s - loss: 0.0162 - accuracy: 0.9983\n",
      "Epoch 353/500\n",
      "38/38 - 0s - loss: 0.0106 - accuracy: 0.9975\n",
      "Epoch 354/500\n",
      "38/38 - 0s - loss: 0.0155 - accuracy: 0.9983\n",
      "Epoch 355/500\n",
      "38/38 - 0s - loss: 0.0125 - accuracy: 0.9983\n",
      "Epoch 356/500\n",
      "38/38 - 0s - loss: 0.0150 - accuracy: 0.9983\n",
      "Epoch 357/500\n",
      "38/38 - 0s - loss: 0.0122 - accuracy: 0.9992\n",
      "Epoch 358/500\n",
      "38/38 - 0s - loss: 0.0166 - accuracy: 0.9983\n",
      "Epoch 359/500\n",
      "38/38 - 0s - loss: 0.0111 - accuracy: 0.9992\n",
      "Epoch 360/500\n",
      "38/38 - 0s - loss: 0.0120 - accuracy: 0.9992\n",
      "Epoch 361/500\n",
      "38/38 - 0s - loss: 0.0144 - accuracy: 0.9975\n",
      "Epoch 362/500\n",
      "38/38 - 0s - loss: 0.0235 - accuracy: 0.9967\n",
      "Epoch 363/500\n",
      "38/38 - 0s - loss: 0.0203 - accuracy: 0.9967\n",
      "Epoch 364/500\n",
      "38/38 - 0s - loss: 0.0143 - accuracy: 0.9975\n",
      "Epoch 365/500\n",
      "38/38 - 0s - loss: 0.0118 - accuracy: 0.9975\n",
      "Epoch 366/500\n",
      "38/38 - 0s - loss: 0.0159 - accuracy: 0.9983\n",
      "Epoch 367/500\n",
      "38/38 - 0s - loss: 0.0142 - accuracy: 0.9983\n",
      "Epoch 368/500\n",
      "38/38 - 0s - loss: 0.0179 - accuracy: 0.9975\n",
      "Epoch 369/500\n",
      "38/38 - 0s - loss: 0.0147 - accuracy: 0.9975\n",
      "Epoch 370/500\n",
      "38/38 - 0s - loss: 0.0151 - accuracy: 0.9967\n",
      "Epoch 371/500\n",
      "38/38 - 0s - loss: 0.0107 - accuracy: 0.9992\n",
      "Epoch 372/500\n",
      "38/38 - 0s - loss: 0.0161 - accuracy: 0.9975\n",
      "Epoch 373/500\n",
      "38/38 - 0s - loss: 0.0136 - accuracy: 0.9958\n",
      "Epoch 374/500\n",
      "38/38 - 0s - loss: 0.0146 - accuracy: 0.9983\n",
      "Epoch 375/500\n",
      "38/38 - 0s - loss: 0.0164 - accuracy: 0.9983\n",
      "Epoch 376/500\n",
      "38/38 - 0s - loss: 0.0155 - accuracy: 0.9967\n",
      "Epoch 377/500\n",
      "38/38 - 0s - loss: 0.0103 - accuracy: 0.9992\n",
      "Epoch 378/500\n",
      "38/38 - 0s - loss: 0.0188 - accuracy: 0.9967\n",
      "Epoch 379/500\n",
      "38/38 - 0s - loss: 0.0432 - accuracy: 0.9908\n",
      "Epoch 380/500\n",
      "38/38 - 0s - loss: 0.0537 - accuracy: 0.9842\n",
      "Epoch 381/500\n",
      "38/38 - 0s - loss: 0.0604 - accuracy: 0.9817\n",
      "Epoch 382/500\n",
      "38/38 - 0s - loss: 0.0246 - accuracy: 0.9950\n",
      "Epoch 383/500\n",
      "38/38 - 0s - loss: 0.0203 - accuracy: 0.9975\n",
      "Epoch 384/500\n",
      "38/38 - 0s - loss: 0.0385 - accuracy: 0.9900\n",
      "Epoch 385/500\n",
      "38/38 - 0s - loss: 0.0274 - accuracy: 0.9933\n",
      "Epoch 386/500\n",
      "38/38 - 0s - loss: 0.0226 - accuracy: 0.9958\n",
      "Epoch 387/500\n",
      "38/38 - 0s - loss: 0.0247 - accuracy: 0.9950\n",
      "Epoch 388/500\n",
      "38/38 - 0s - loss: 0.0231 - accuracy: 0.9950\n",
      "Epoch 389/500\n",
      "38/38 - 0s - loss: 0.0108 - accuracy: 0.9983\n",
      "Epoch 390/500\n",
      "38/38 - 0s - loss: 0.0132 - accuracy: 0.9992\n",
      "Epoch 391/500\n",
      "38/38 - 0s - loss: 0.0091 - accuracy: 0.9983\n",
      "Epoch 392/500\n",
      "38/38 - 0s - loss: 0.0170 - accuracy: 0.9975\n",
      "Epoch 393/500\n",
      "38/38 - 0s - loss: 0.0069 - accuracy: 0.9992\n",
      "Epoch 394/500\n",
      "38/38 - 0s - loss: 0.0087 - accuracy: 0.9992\n",
      "Epoch 395/500\n",
      "38/38 - 0s - loss: 0.0139 - accuracy: 0.9983\n",
      "Epoch 396/500\n",
      "38/38 - 0s - loss: 0.0128 - accuracy: 0.9967\n",
      "Epoch 397/500\n",
      "38/38 - 0s - loss: 0.0104 - accuracy: 0.9983\n",
      "Epoch 398/500\n",
      "38/38 - 0s - loss: 0.0097 - accuracy: 0.9992\n",
      "Epoch 399/500\n",
      "38/38 - 0s - loss: 0.0074 - accuracy: 0.9983\n",
      "Epoch 400/500\n",
      "38/38 - 0s - loss: 0.0158 - accuracy: 0.9983\n",
      "Epoch 401/500\n",
      "38/38 - 0s - loss: 0.0206 - accuracy: 0.9992\n",
      "Epoch 402/500\n",
      "38/38 - 0s - loss: 0.0151 - accuracy: 0.9975\n",
      "Epoch 403/500\n",
      "38/38 - 0s - loss: 0.0135 - accuracy: 0.9983\n",
      "Epoch 404/500\n",
      "38/38 - 0s - loss: 0.0087 - accuracy: 0.9992\n",
      "Epoch 405/500\n",
      "38/38 - 0s - loss: 0.0139 - accuracy: 0.9975\n",
      "Epoch 406/500\n",
      "38/38 - 0s - loss: 0.0078 - accuracy: 0.9983\n",
      "Epoch 407/500\n",
      "38/38 - 0s - loss: 0.0059 - accuracy: 0.9992\n",
      "Epoch 408/500\n",
      "38/38 - 0s - loss: 0.0107 - accuracy: 0.9992\n",
      "Epoch 409/500\n",
      "38/38 - 0s - loss: 0.0086 - accuracy: 0.9983\n",
      "Epoch 410/500\n",
      "38/38 - 0s - loss: 0.0147 - accuracy: 0.9975\n",
      "Epoch 411/500\n",
      "38/38 - 0s - loss: 0.0136 - accuracy: 0.9983\n",
      "Epoch 412/500\n",
      "38/38 - 0s - loss: 0.0220 - accuracy: 0.9983\n",
      "Epoch 413/500\n",
      "38/38 - 0s - loss: 0.0085 - accuracy: 0.9992\n",
      "Epoch 414/500\n",
      "38/38 - 0s - loss: 0.0095 - accuracy: 0.9992\n",
      "Epoch 415/500\n",
      "38/38 - 0s - loss: 0.0069 - accuracy: 0.9992\n",
      "Epoch 416/500\n",
      "38/38 - 0s - loss: 0.0097 - accuracy: 0.9992\n",
      "Epoch 417/500\n",
      "38/38 - 0s - loss: 0.0097 - accuracy: 0.9975\n",
      "Epoch 418/500\n",
      "38/38 - 0s - loss: 0.0189 - accuracy: 0.9958\n",
      "Epoch 419/500\n",
      "38/38 - 0s - loss: 0.0157 - accuracy: 0.9958\n",
      "Epoch 420/500\n",
      "38/38 - 0s - loss: 0.0171 - accuracy: 0.9967\n",
      "Epoch 421/500\n",
      "38/38 - 0s - loss: 0.0154 - accuracy: 0.9967\n",
      "Epoch 422/500\n",
      "38/38 - 0s - loss: 0.1241 - accuracy: 0.9641\n",
      "Epoch 423/500\n",
      "38/38 - 0s - loss: 0.1212 - accuracy: 0.9725\n",
      "Epoch 424/500\n",
      "38/38 - 0s - loss: 0.1128 - accuracy: 0.9683\n",
      "Epoch 425/500\n",
      "38/38 - 0s - loss: 0.1031 - accuracy: 0.9733\n",
      "Epoch 426/500\n",
      "38/38 - 0s - loss: 0.0392 - accuracy: 0.9933\n",
      "Epoch 427/500\n",
      "38/38 - 0s - loss: 0.0182 - accuracy: 0.9983\n",
      "Epoch 428/500\n",
      "38/38 - 0s - loss: 0.0165 - accuracy: 0.9975\n",
      "Epoch 429/500\n",
      "38/38 - 0s - loss: 0.0138 - accuracy: 0.9975\n",
      "Epoch 430/500\n",
      "38/38 - 0s - loss: 0.0116 - accuracy: 0.9983\n",
      "Epoch 431/500\n",
      "38/38 - 0s - loss: 0.0084 - accuracy: 0.9992\n",
      "Epoch 432/500\n",
      "38/38 - 0s - loss: 0.0135 - accuracy: 0.9967\n",
      "Epoch 433/500\n",
      "38/38 - 0s - loss: 0.0104 - accuracy: 0.9983\n",
      "Epoch 434/500\n",
      "38/38 - 0s - loss: 0.0082 - accuracy: 0.9992\n",
      "Epoch 435/500\n",
      "38/38 - 0s - loss: 0.0092 - accuracy: 0.9992\n",
      "Epoch 436/500\n",
      "38/38 - 0s - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 437/500\n",
      "38/38 - 0s - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "38/38 - 0s - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "38/38 - 0s - loss: 0.0048 - accuracy: 0.9992\n",
      "Epoch 440/500\n",
      "38/38 - 0s - loss: 0.0049 - accuracy: 0.9992\n",
      "Epoch 441/500\n",
      "38/38 - 0s - loss: 0.0080 - accuracy: 0.9983\n",
      "Epoch 442/500\n",
      "38/38 - 0s - loss: 0.0063 - accuracy: 0.9983\n",
      "Epoch 443/500\n",
      "38/38 - 0s - loss: 0.0083 - accuracy: 0.9983\n",
      "Epoch 444/500\n",
      "38/38 - 0s - loss: 0.0094 - accuracy: 0.9992\n",
      "Epoch 445/500\n",
      "38/38 - 0s - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "38/38 - 0s - loss: 0.0081 - accuracy: 0.9992\n",
      "Epoch 447/500\n",
      "38/38 - 0s - loss: 0.0103 - accuracy: 0.9992\n",
      "Epoch 448/500\n",
      "38/38 - 0s - loss: 0.0116 - accuracy: 0.9975\n",
      "Epoch 449/500\n",
      "38/38 - 0s - loss: 0.0072 - accuracy: 0.9992\n",
      "Epoch 450/500\n",
      "38/38 - 0s - loss: 0.0091 - accuracy: 0.9992\n",
      "Epoch 451/500\n",
      "38/38 - 0s - loss: 0.0102 - accuracy: 0.9975\n",
      "Epoch 452/500\n",
      "38/38 - 0s - loss: 0.0082 - accuracy: 0.9992\n",
      "Epoch 453/500\n",
      "38/38 - 0s - loss: 0.0104 - accuracy: 0.9975\n",
      "Epoch 454/500\n",
      "38/38 - 0s - loss: 0.0133 - accuracy: 0.9975\n",
      "Epoch 455/500\n",
      "38/38 - 0s - loss: 0.0080 - accuracy: 0.9992\n",
      "Epoch 456/500\n",
      "38/38 - 0s - loss: 0.0133 - accuracy: 0.9975\n",
      "Epoch 457/500\n",
      "38/38 - 0s - loss: 0.0087 - accuracy: 0.9992\n",
      "Epoch 458/500\n",
      "38/38 - 0s - loss: 0.0102 - accuracy: 0.9975\n",
      "Epoch 459/500\n",
      "38/38 - 0s - loss: 0.0103 - accuracy: 0.9975\n",
      "Epoch 460/500\n",
      "38/38 - 0s - loss: 0.0205 - accuracy: 0.9958\n",
      "Epoch 461/500\n",
      "38/38 - 0s - loss: 0.0105 - accuracy: 0.9992\n",
      "Epoch 462/500\n",
      "38/38 - 0s - loss: 0.0104 - accuracy: 0.9983\n",
      "Epoch 463/500\n",
      "38/38 - 0s - loss: 0.0069 - accuracy: 0.9983\n",
      "Epoch 464/500\n",
      "38/38 - 0s - loss: 0.0115 - accuracy: 0.9983\n",
      "Epoch 465/500\n",
      "38/38 - 0s - loss: 0.0105 - accuracy: 0.9983\n",
      "Epoch 466/500\n",
      "38/38 - 0s - loss: 0.0085 - accuracy: 0.9983\n",
      "Epoch 467/500\n",
      "38/38 - 0s - loss: 0.0134 - accuracy: 0.9967\n",
      "Epoch 468/500\n",
      "38/38 - 0s - loss: 0.0057 - accuracy: 0.9983\n",
      "Epoch 469/500\n",
      "38/38 - 0s - loss: 0.0131 - accuracy: 0.9975\n",
      "Epoch 470/500\n",
      "38/38 - 0s - loss: 0.0098 - accuracy: 0.9975\n",
      "Epoch 471/500\n",
      "38/38 - 0s - loss: 0.0124 - accuracy: 0.9983\n",
      "Epoch 472/500\n",
      "38/38 - 0s - loss: 0.0059 - accuracy: 0.9983\n",
      "Epoch 473/500\n",
      "38/38 - 0s - loss: 0.0113 - accuracy: 0.9983\n",
      "Epoch 474/500\n",
      "38/38 - 0s - loss: 0.0073 - accuracy: 0.9983\n",
      "Epoch 475/500\n",
      "38/38 - 0s - loss: 0.0126 - accuracy: 0.9950\n",
      "Epoch 476/500\n",
      "38/38 - 0s - loss: 0.0124 - accuracy: 0.9975\n",
      "Epoch 477/500\n",
      "38/38 - 0s - loss: 0.0096 - accuracy: 0.9983\n",
      "Epoch 478/500\n",
      "38/38 - 0s - loss: 0.0173 - accuracy: 0.9958\n",
      "Epoch 479/500\n",
      "38/38 - 0s - loss: 0.0344 - accuracy: 0.9883\n",
      "Epoch 480/500\n",
      "38/38 - 0s - loss: 0.0254 - accuracy: 0.9950\n",
      "Epoch 481/500\n",
      "38/38 - 0s - loss: 0.0706 - accuracy: 0.9783\n",
      "Epoch 482/500\n",
      "38/38 - 0s - loss: 0.0346 - accuracy: 0.9933\n",
      "Epoch 483/500\n",
      "38/38 - 0s - loss: 0.1020 - accuracy: 0.9800\n",
      "Epoch 484/500\n",
      "38/38 - 0s - loss: 0.0717 - accuracy: 0.9817\n",
      "Epoch 485/500\n",
      "38/38 - 0s - loss: 0.0270 - accuracy: 0.9917\n",
      "Epoch 486/500\n",
      "38/38 - 0s - loss: 0.0548 - accuracy: 0.9917\n",
      "Epoch 487/500\n",
      "38/38 - 0s - loss: 0.0505 - accuracy: 0.9842\n",
      "Epoch 488/500\n",
      "38/38 - 0s - loss: 0.0121 - accuracy: 0.9983\n",
      "Epoch 489/500\n",
      "38/38 - 0s - loss: 0.0083 - accuracy: 0.9992\n",
      "Epoch 490/500\n",
      "38/38 - 0s - loss: 0.0086 - accuracy: 0.9983\n",
      "Epoch 491/500\n",
      "38/38 - 0s - loss: 0.0075 - accuracy: 0.9983\n",
      "Epoch 492/500\n",
      "38/38 - 0s - loss: 0.0076 - accuracy: 0.9992\n",
      "Epoch 493/500\n",
      "38/38 - 0s - loss: 0.0064 - accuracy: 0.9992\n",
      "Epoch 494/500\n",
      "38/38 - 0s - loss: 0.0067 - accuracy: 0.9992\n",
      "Epoch 495/500\n",
      "38/38 - 0s - loss: 0.0077 - accuracy: 0.9992\n",
      "Epoch 496/500\n",
      "38/38 - 0s - loss: 0.0103 - accuracy: 0.9983\n",
      "Epoch 497/500\n",
      "38/38 - 0s - loss: 0.0083 - accuracy: 0.9967\n",
      "Epoch 498/500\n",
      "38/38 - 0s - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "38/38 - 0s - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "38/38 - 0s - loss: 0.0033 - accuracy: 0.9992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ca263ea7c8>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the neural network model to the training data\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=500,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prediction function \n",
    "def predict(model, X_scaler, y_scaler, user_inputs):\n",
    "    # get the user input data \n",
    "    fixed_acidity = user_inputs[\"fixed_acidity\"]\n",
    "    volatile_acidity = user_inputs[\"volatile_acidity\"]\n",
    "    citric_acid = user_inputs[\"citric_acid\"]\n",
    "    residual_sugar = user_inputs[\"residual_sugar\"]\n",
    "    chlorides = user_inputs[\"chlorides\"]\n",
    "    free_sulfur_dioxide = user_inputs[\"free_sulfur_dioxide\"]\n",
    "    total_sulfur_dioxide = user_inputs[\"total_sulfur_dioxide\"]\n",
    "    density = user_inputs[\"density\"]\n",
    "    pH = user_inputs[\"pH\"]\n",
    "    sulphates = user_inputs[\"sulphates\"]\n",
    "    alcohol = user_inputs[\"alcohol\"]\n",
    "\n",
    "    # store input data into df \n",
    "    input_df = pd.DataFrame({\n",
    "        \"fixed_acidity\": [fixed_acidity],\n",
    "        \"volatile_acidity\": [volatile_acidity],\n",
    "        \"citric_acid\": [citric_acid],\n",
    "        \"residual_sugar\": [residual_sugar],\n",
    "        \"chlorides\": [chlorides],\n",
    "        \"free_sulfur_dioxide\": [free_sulfur_dioxide],\n",
    "        \"total_sulfur_dioxide\": [total_sulfur_dioxide],\n",
    "        \"density\": [density],\n",
    "        \"pH\": [pH],\n",
    "        \"sulphates\": [sulphates],\n",
    "        \"alcohol\": [alcohol]\n",
    "    })\n",
    "\n",
    "    # scale the X input df \n",
    "    X_scaled = X_scaler.transform(input_df)\n",
    "\n",
    "    # obtain prediction (y) \n",
    "    prediction_scaled = model.predict(X_scaled)\n",
    "    \n",
    "    # scale prediction to human readable terms\n",
    "    prediction = y_scaler.inverse_transform(prediction_scaled)\n",
    "\n",
    "    return prediction \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare user_input to go into the predict function \n",
    "def scaledata(X_scaler, user_inputs):\n",
    "    # get the user input data \n",
    "    fixed_acidity = user_inputs[\"fixed_acidity\"]\n",
    "    volatile_acidity = user_inputs[\"volatile_acidity\"]\n",
    "    citric_acid = user_inputs[\"citric_acid\"]\n",
    "    residual_sugar = user_inputs[\"residual_sugar\"]\n",
    "    chlorides = user_inputs[\"chlorides\"]\n",
    "    free_sulfur_dioxide = user_inputs[\"free_sulfur_dioxide\"]\n",
    "    total_sulfur_dioxide = user_inputs[\"total_sulfur_dioxide\"]\n",
    "    density = user_inputs[\"density\"]\n",
    "    pH = user_inputs[\"pH\"]\n",
    "    sulphates = user_inputs[\"sulphates\"]\n",
    "    alcohol = user_inputs[\"alcohol\"]\n",
    "\n",
    "    # store input data into df \n",
    "    input_df = pd.DataFrame({\n",
    "        \"fixed_acidity\": [fixed_acidity],\n",
    "        \"volatile_acidity\": [volatile_acidity],\n",
    "        \"citric_acid\": [citric_acid],\n",
    "        \"residual_sugar\": [residual_sugar],\n",
    "        \"chlorides\": [chlorides],\n",
    "        \"free_sulfur_dioxide\": [free_sulfur_dioxide],\n",
    "        \"total_sulfur_dioxide\": [total_sulfur_dioxide],\n",
    "        \"density\": [density],\n",
    "        \"pH\": [pH],\n",
    "        \"sulphates\": [sulphates],\n",
    "        \"alcohol\": [alcohol]\n",
    "    })\n",
    "\n",
    "    # scale the X input df \n",
    "    X_scaled = X_scaler.transform(input_df)\n",
    "\n",
    "    return X_scaled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow          predict quality score is: 6   vs expected result of 6\n",
      "Linear model        predict quality score is: 5.0 vs expected result of 6\n",
      "KNN model           predict quality score is: 5   vs expected result of 6\n",
      "Random Forest model predict quality score is: 6   vs expected result of 6\n"
     ]
    }
   ],
   "source": [
    "# Test a single prediction using different models \n",
    "# Tensor flow model: accuracy: 0.9950\n",
    "# linearmodel : Score = 0.338\n",
    "# RandomForestClassifiermodel : Score = 0.6825\n",
    "# knn : Score = 0.6125\n",
    "\n",
    "index_on_test_dataset = 155\n",
    "user_inputs = X_test.iloc[index_on_test_dataset]\n",
    "expectedresult = y_test[index_on_test_dataset][0]\n",
    "\n",
    "# Using Tensorflow model\n",
    "X_scaled = scaledata(X_scaler, user_inputs)\n",
    "encoded_predictions = model.predict_classes(X_scaled[:5])\n",
    "prediction_labels = label_encoder.inverse_transform(encoded_predictions)\n",
    "print(f\"Tensorflow          predict quality score is: {prediction_labels[0]}   vs expected result of {expectedresult}\")\n",
    "\n",
    "# Using linearmodel\n",
    "print(f\"Linear model        predict quality score is: {predict(linearmodel, X_scaler, y_scaler, user_inputs)[0][0].round(1)} vs expected result of {expectedresult}\")\n",
    "\n",
    "#Using KNN model\n",
    "X_scaled = scaledata(X_scaler, user_inputs)\n",
    "predicted_quality = knn.predict(X_scaled)\n",
    "print(f\"KNN model           predict quality score is: {predicted_quality[0]}   vs expected result of {expectedresult}\")\n",
    "\n",
    "#Using random forest model\n",
    "X_scaled = scaledata(X_scaler, user_inputs)\n",
    "predicted_quality = RandomForestClassifiermodel.predict(X_scaled)\n",
    "print(f\"Random Forest model predict quality score is: {predicted_quality[0]}   vs expected result of {expectedresult}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../app/static/py/encoder.sav']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save model\n",
    "import joblib \n",
    "\n",
    "model.save(\"../app/static/py/model_trained.h5\")\n",
    "joblib.dump(y_scaler, \"../app/static/py/y_scaler.sav\")\n",
    "joblib.dump(X_scaler, \"../app/static/py/x_scaler.sav\")\n",
    "joblib.dump(label_encoder, \"../app/static/py/encoder.sav\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "23a582b2fcb0d9f1a6df63352f294e1d6ca5ce9199f319a44fc346f4901363b4"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('PythonData')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
